{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/82763928", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/82763928/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/82763928/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.13.0%2Bcpu", "id": 82763928, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4E7uCY", "tag_name": "v1.13.0+cpu", "target_commitish": "release/1.13", "name": "Intel\u00ae Extension for PyTorch* v1.13.0+cpu Release Notes", "draft": false, "prerelease": false, "created_at": "2022-11-11T05:56:44Z", "published_at": "2022-11-11T06:26:56Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233459", "id": 84233459, "node_id": "RA_kwDOD0MuUM4FBUzz", "name": "intel_extension_for_pytorch-1.13.0+cpu-cp310-cp310-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41344546, "download_count": 8, "created_at": "2022-11-11T06:25:22Z", "updated_at": "2022-11-11T06:25:27Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0%2Bcpu-cp310-cp310-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233469", "id": 84233469, "node_id": "RA_kwDOD0MuUM4FBUz9", "name": "intel_extension_for_pytorch-1.13.0+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41385965, "download_count": 1, "created_at": "2022-11-11T06:25:35Z", "updated_at": "2022-11-11T06:25:39Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233467", "id": 84233467, "node_id": "RA_kwDOD0MuUM4FBUz7", "name": "intel_extension_for_pytorch-1.13.0+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41368696, "download_count": 1, "created_at": "2022-11-11T06:25:31Z", "updated_at": "2022-11-11T06:25:35Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233463", "id": 84233463, "node_id": "RA_kwDOD0MuUM4FBUz3", "name": "intel_extension_for_pytorch-1.13.0+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 40678675, "download_count": 2, "created_at": "2022-11-11T06:25:27Z", "updated_at": "2022-11-11T06:25:31Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0%2Bcpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233473", "id": 84233473, "node_id": "RA_kwDOD0MuUM4FBU0B", "name": "intel_extension_for_pytorch-1.13.0-cp310-cp310-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41354184, "download_count": 8, "created_at": "2022-11-11T06:25:40Z", "updated_at": "2022-11-11T06:25:45Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0-cp310-cp310-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233502", "id": 84233502, "node_id": "RA_kwDOD0MuUM4FBU0e", "name": "intel_extension_for_pytorch-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41396097, "download_count": 6, "created_at": "2022-11-11T06:25:55Z", "updated_at": "2022-11-11T06:26:00Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233494", "id": 84233494, "node_id": "RA_kwDOD0MuUM4FBU0W", "name": "intel_extension_for_pytorch-1.13.0-cp38-cp38-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41376543, "download_count": 68, "created_at": "2022-11-11T06:25:50Z", "updated_at": "2022-11-11T06:25:55Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0-cp38-cp38-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233486", "id": 84233486, "node_id": "RA_kwDOD0MuUM4FBU0O", "name": "intel_extension_for_pytorch-1.13.0-cp39-cp39-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 40687344, "download_count": 10, "created_at": "2022-11-11T06:25:45Z", "updated_at": "2022-11-11T06:25:50Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/intel_extension_for_pytorch-1.13.0-cp39-cp39-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233458", "id": 84233458, "node_id": "RA_kwDOD0MuUM4FBUzy", "name": "libintel-ext-pt-1.13.0+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 17566340, "download_count": 4, "created_at": "2022-11-11T06:25:21Z", "updated_at": "2022-11-11T06:25:24Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/libintel-ext-pt-1.13.0%2Bcpu.run"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/84233454", "id": 84233454, "node_id": "RA_kwDOD0MuUM4FBUzu", "name": "libintel-ext-pt-cxx11-abi-1.13.0+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 17453312, "download_count": 1, "created_at": "2022-11-11T06:25:16Z", "updated_at": "2022-11-11T06:25:21Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.13.0%2Bcpu/libintel-ext-pt-cxx11-abi-1.13.0%2Bcpu.run"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.13.0+cpu", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.13.0+cpu", "body": "We are pleased to announce the release of Intel\u00ae Extension for PyTorch* 1.13.0-cpu which accompanies PyTorch 1.13. This release is highlighted with quite a few usability features which help users to get good performance and accuracy on CPU with less effort. We also added a couple of performance features as always. Check out the feature summary below.\r\n- Usability Features\r\n1. **Automatic channels last format conversion**: Channels last conversion is now applied automatically to PyTorch modules with `ipex.optimize` by default. Users don't have to explicitly convert input and weight for CV models.\r\n2. **Code-free optimization** (experimental): `ipex.optimize` is automatically applied to PyTorch modules without the need of code changes when the PyTorch program is started with the IPEX launcher via the new `--auto-ipex` option.\r\n3. **Graph capture mode** of `ipex.optimize` (experimental): A new boolean flag `graph_mode` (default off) was added to `ipex.optimize`, when turned on, converting the eager-mode PyTorch module into graph(s) to get the best of graph optimization.\r\n4. **INT8 quantization accuracy autotune** (experimental): A new quantization API `ipex.quantization.autotune` was added to refine the default IPEX quantization recipe via autotuning algorithms for better accuracy.\r\n5. **Hypertune** (experimental) is a new tool added on top of IPEX launcher to automatically identify the good configurations for best throughput via hyper-parameter tuning.\r\n6. **ipexrun**: The counterpart of **torchrun**, is a shortcut added for invoking IPEX launcher.\r\n- Performance Features\r\n1. Packed MKL SGEMM landed as the default kernel option for FP32 Linear, bringing up-to 20% geomean speedup for real-time NLP tasks.\r\n2. DL compiler is now turned on by default with oneDNN fusion and gives additional performance boost for INT8 models.\r\n\r\n# Highlights\r\n* **Automatic channels last format conversion**: Channels last conversion is now applied to PyTorch modules automatically with `ipex.optimize` by default for both training and inference scenarios. Users don't have to explicitly convert input and weight for CV models.\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n# No need to do explicitly format conversion\r\n# m = m.to(format=torch.channels_last)\r\n# x = x.to(format=torch.channels_last)\r\n# for inference\r\nm = ipex.optimize(m)\r\nm(x)\r\n# for training\r\nm, optimizer = ipex.optimize(m, optimizer)\r\nm(x)\r\n```\r\n* **Code-free optimization** (experimental): `ipex.optimize` is automatically applied to PyTorch modules without the need of code changes when the PyTorch program is started with the IPEX launcher via the new `--auto-ipex` option.\r\n### Example: QA case in HuggingFace\r\n```bash\r\n# original command\r\nipexrun --use_default_allocator --ninstance 2 --ncore_per_instance 28 run_qa.py \\\r\n  --model_name_or_path bert-base-uncased --dataset_name squad --do_eval \\\r\n  --per_device_train_batch_size 12 --learning_rate 3e-5 --num_train_epochs 2 \\\r\n  --max_seq_length 384 --doc_stride 128 --output_dir /tmp/debug_squad/\r\n\r\n# automatically apply bfloat16 optimization (--auto-ipex --dtype bfloat16)\r\nipexrun --use_default_allocator --ninstance 2 --ncore_per_instance 28 --auto_ipex --dtype bfloat16 run_qa.py \\\r\n  --model_name_or_path bert-base-uncased --dataset_name squad --do_eval \\\r\n  --per_device_train_batch_size 12 --learning_rate 3e-5 --num_train_epochs 2 \\\r\n  --max_seq_length 384 --doc_stride 128 --output_dir /tmp/debug_squad/\r\n```\r\n\r\n* **Graph capture mode** of `ipex.optimize` (experimental): A new boolean flag `graph_mode` (default off) was added to `ipex.optimize`, when turned on, converting the eager-mode PyTorch module into graph(s) to get the best of graph optimization. Under the hood, it combines the goodness of both TorchScript tracing and TorchDynamo to get as max graph scope as possible. Currently, it only supports FP32 and BF16 inference. INT8 inference and training support are under way.\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\nmodel = ...\r\nmodel.load_state_dict(torch.load(PATH))\r\nmodel.eval()\r\noptimized_model = ipex.optimize(model, graph_mode=True)\r\n```\r\n\r\n* **INT8 quantization accuracy autotune** (experimental): A new quantization API `ipex.quantization.autotune` was added to refine the default IPEX quantization recipe via autotuning algorithms for better accuracy. This is an optional API to invoke (after `prepare` and before `convert`) for scenarios when the accuracy of default quantization recipe of IPEX cannot meet the requirement. The current implementation is powered by Intel Neural Compressor (INC).\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n# Calibrate the model\r\nqconfig = ipex.quantization.default_static_qconfig\r\ncalibrated_model = ipex.quantization.prepare(model_to_be_calibrated, qconfig, example_inputs=example_inputs)\r\nfor data in calibration_data_set:\r\n    calibrated_model(data)\r\n# Autotune the model\r\ncalib_dataloader = torch.utils.data.DataLoader(...)\r\ndef eval_func(model):\r\n    # Return accuracy value\r\n    ...\r\n    return accuracy\r\ntuned_model = ipex.quantization.autotune(\r\n                 calibrated_model, calib_dataloader, eval_func,\r\n                 sampling_sizes=[100], accuracy_criterion={'relative': 0.01}, tuning_time=0\r\n              )\r\n# Convert the model to jit model\r\nquantized_model = ipex.quantization.convert(tuned_model)\r\nwith torch.no_grad():\r\n    traced_model = torch.jit.trace(quantized_model, example_input)\r\n    traced_model = torch.jit.freeze(traced_model)\r\n# Do inference\r\ny = traced_model(x)\r\n```\r\n\r\n* **Hypertune** (experimental) is a new tool added on top of IPEX launcher to automatically identify the good configurations for best throughput via hyper-parameter tuning.\r\n```bash\r\npython -m intel_extension_for_pytorch.cpu.launch.hypertune --conf_file <your_conf_file> <your_python_script> [args]\r\n```\r\n\r\n# Known Issues\r\nPlease check at [Known Issues webpage](https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/performance_tuning/known_issues.html).", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/82763928/reactions", "total_count": 6, "+1": 0, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 5, "rocket": 1, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/81441463", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/81441463/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/81441463/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.10.200%2Bgpu", "id": 81441463, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4E2rK3", "tag_name": "v1.10.200+gpu", "target_commitish": "xpu-master", "name": "Intel\u00ae Extension for PyTorch* v1.10.200+gpu Release Notes", "draft": false, "prerelease": false, "created_at": "2022-10-31T05:31:05Z", "published_at": "2022-10-31T05:49:20Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82684913", "id": 82684913, "node_id": "RA_kwDOD0MuUM4E7avx", "name": "intel_extension_for_pytorch-1.10.200+gpu-cp36-cp36m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 242213054, "download_count": 2, "created_at": "2022-10-29T05:24:39Z", "updated_at": "2022-10-29T05:25:45Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/intel_extension_for_pytorch-1.10.200%2Bgpu-cp36-cp36m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82684625", "id": 82684625, "node_id": "RA_kwDOD0MuUM4E7arR", "name": "intel_extension_for_pytorch-1.10.200+gpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 242213320, "download_count": 3, "created_at": "2022-10-29T05:22:08Z", "updated_at": "2022-10-29T05:23:20Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/intel_extension_for_pytorch-1.10.200%2Bgpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82685132", "id": 82685132, "node_id": "RA_kwDOD0MuUM4E7azM", "name": "intel_extension_for_pytorch-1.10.200+gpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 242248354, "download_count": 9, "created_at": "2022-10-29T05:28:41Z", "updated_at": "2022-10-29T05:29:47Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/intel_extension_for_pytorch-1.10.200%2Bgpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82684743", "id": 82684743, "node_id": "RA_kwDOD0MuUM4E7atH", "name": "intel_extension_for_pytorch-1.10.200+gpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 241638067, "download_count": 101, "created_at": "2022-10-29T05:23:20Z", "updated_at": "2022-10-29T05:24:39Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/intel_extension_for_pytorch-1.10.200%2Bgpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82685009", "id": 82685009, "node_id": "RA_kwDOD0MuUM4E7axR", "name": "torch-1.10.0a0+git3d5f2d4-cp36-cp36m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 155060253, "download_count": 6, "created_at": "2022-10-29T05:25:45Z", "updated_at": "2022-10-29T05:26:28Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/torch-1.10.0a0%2Bgit3d5f2d4-cp36-cp36m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82685036", "id": 82685036, "node_id": "RA_kwDOD0MuUM4E7axs", "name": "torch-1.10.0a0+git3d5f2d4-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 155409599, "download_count": 3, "created_at": "2022-10-29T05:26:28Z", "updated_at": "2022-10-29T05:27:11Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/torch-1.10.0a0%2Bgit3d5f2d4-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82685090", "id": 82685090, "node_id": "RA_kwDOD0MuUM4E7ayi", "name": "torch-1.10.0a0+git3d5f2d4-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 155312626, "download_count": 10, "created_at": "2022-10-29T05:27:11Z", "updated_at": "2022-10-29T05:27:59Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/torch-1.10.0a0%2Bgit3d5f2d4-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/82685119", "id": 82685119, "node_id": "RA_kwDOD0MuUM4E7ay_", "name": "torch-1.10.0a0+git3d5f2d4-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 155300547, "download_count": 78, "created_at": "2022-10-29T05:27:59Z", "updated_at": "2022-10-29T05:28:41Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.200%2Bgpu/torch-1.10.0a0%2Bgit3d5f2d4-cp39-cp39-linux_x86_64.whl"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.10.200+gpu", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.10.200+gpu", "body": "Intel\u00ae Extension for PyTorch\\* v1.10.200+gpu extends PyTorch\\* 1.10 with up-to-date features and optimizations on XPU for an extra performance boost on Intel Graphics cards. XPU is a user visible device that is a counterpart of the well-known CPU and CUDA in the PyTorch\\* community. XPU represents an Intel-specific kernel and graph optimizations for various \u201cconcrete\u201d devices. The XPU runtime will choose the actual device when executing AI workloads on the XPU device. The default selected device is Intel GPU. XPU kernels from Intel\u00ae Extension for PyTorch\\* are written in [DPC++](https://github.com/intel/llvm#oneapi-dpc-compiler) that supports [SYCL language](https://registry.khronos.org/SYCL/specs/sycl-2020/html/sycl-2020.html) and also a number of [DPC++ extensions](https://github.com/intel/llvm/tree/sycl/sycl/doc/extensions).\r\n\r\n### Highlights\r\n\r\nThis release introduces specific XPU solution optimizations on Intel\u00ae Data Center GPU Flex Series 170. Optimized operators and kernels are implemented and registered through PyTorch\\* dispatching mechanism for the XPU device. These operators and kernels are accelerated on Intel GPU hardware from the corresponding native vectorization and matrix calculation features. In graph mode, additional operator fusions are supported to reduce operator/kernel invocation overheads, and thus increase performance.\r\n\r\nThis release provides the following features:\r\n- Auto Mixed Precision (AMP)\r\n  - support of AMP with BFloat16 and Float16 optimization of GPU operators\r\n- Channels Last\r\n  - support of channels\\_last (NHWC) memory format for most key GPU operators\r\n- DPC++ Extension\r\n  - mechanism to create PyTorch\\* operators with custom DPC++ kernels running on the XPU device\r\n- Optimized Fusion\r\n  - support of SGD/AdamW fusion for both FP32 and BF16 precision\r\n\r\nThis release supports the following fusion patterns in PyTorch\\* JIT mode:\r\n\r\n- Conv2D + ReLU\r\n- Conv2D + Sum\r\n- Conv2D + Sum + ReLU\r\n- Pad + Conv2d\r\n- Conv2D + SiLu\r\n- Permute + Contiguous\r\n- Conv3D + ReLU\r\n- Conv3D + Sum\r\n- Conv3D + Sum + ReLU\r\n- Linear + ReLU\r\n- Linear + Sigmoid\r\n- Linear + Div(scalar)\r\n- Linear + GeLu\r\n- Linear + GeLu\\_\r\n- T + Addmm\r\n- T + Addmm + ReLu\r\n- T + Addmm + Sigmoid\r\n- T + Addmm + Dropout\r\n- T + Matmul\r\n- T + Matmul + Add\r\n- T + Matmul + Add + GeLu\r\n- T + Matmul + Add + Dropout\r\n- Transpose + Matmul\r\n- Transpose + Matmul + Div\r\n- Transpose + Matmul + Div + Add\r\n- MatMul + Add\r\n- MatMul + Div\r\n- Dequantize + PixelShuffle\r\n- Dequantize + PixelShuffle + Quantize\r\n- Mul + Add\r\n- Add + ReLU\r\n- Conv2D + Leaky\\_relu\r\n- Conv2D + Leaky\\_relu\\_\r\n- Conv2D + Sigmoid\r\n- Conv2D + Dequantize\r\n- Softplus + Tanh\r\n- Softplus + Tanh + Mul\r\n- Conv2D + Dequantize + Softplus + Tanh + Mul\r\n- Conv2D + Dequantize + Softplus + Tanh + Mul + Quantize\r\n- Conv2D + Dequantize + Softplus + Tanh + Mul + Quantize + Add\r\n\r\n### Known Issues\r\n\r\n- [CRITICAL ERROR] Kernel 'XXX' removed due to usage of FP64 instructions unsupported by the targeted hardware\r\n\r\n    FP64 is not natively supported by the [Intel\u00ae Data Center GPU Flex Series](https://www.intel.com/content/www/us/en/products/docs/discrete-gpus/data-center-gpu/flex-series/overview.html) platform. If you run any AI workload on that platform and receive this error message, it means a kernel requiring FP64 instructions is removed and not executed, hence the accuracy of the whole workload is wrong.\r\n\r\n- symbol undefined caused by `_GLIBCXX_USE_CXX11_ABI`\r\n\r\n    ```bash\r\n    ImportError: undefined symbol: _ZNK5torch8autograd4Node4nameB5cxx11Ev\r\n    ```\r\n    \r\n    DPC++ does not support `_GLIBCXX_USE_CXX11_ABI=0`, Intel\u00ae Extension for PyTorch\\* is always compiled with `_GLIBCXX_USE_CXX11_ABI=1`. This symbol undefined issue appears when PyTorch\\* is compiled with `_GLIBCXX_USE_CXX11_ABI=0`. Update PyTorch\\* CMAKE file to set `_GLIBCXX_USE_CXX11_ABI=1` and compile PyTorch\\* with particular compiler which supports `_GLIBCXX_USE_CXX11_ABI`. We recommend using gcc version 9.4.0 on ubuntu 20.04.\r\n\r\n- Can't find oneMKL library when build Intel\u00ae Extension for PyTorch\\* without oneMKL\r\n\r\n    ```bash\r\n    /usr/bin/ld: cannot find -lmkl_sycl\r\n    /usr/bin/ld: cannot find -lmkl_intel_ilp64\r\n    /usr/bin/ld: cannot find -lmkl_core\r\n    /usr/bin/ld: cannot find -lmkl_tbb_thread\r\n    dpcpp: error: linker command failed with exit code 1 (use -v to see invocation)\r\n    ```\r\n    \r\n    When PyTorch\\* is built with oneMKL library and Intel\u00ae Extension for PyTorch\\* is built without oneMKL library, this linker issue may occur. Resolve it by setting:\r\n    \r\n    ```bash\r\n    export USE_ONEMKL=OFF\r\n    export MKL_DPCPP_ROOT=${PATH_To_Your_oneMKL}/__release_lnx/mkl\r\n    ```\r\n    \r\n    Then clean build Intel\u00ae Extension for PyTorch\\*.\r\n\r\n- undefined symbol: mkl\\_lapack\\_dspevd. Intel MKL FATAL ERROR: cannot load libmkl\\_vml\\_avx512.so.2 or libmkl\\_vml\\_def.so.2\r\n\r\n    This issue may occur when Intel\u00ae Extension for PyTorch\\* is built with oneMKL library and PyTorch\\* is not build with any MKL library. The oneMKL kernel may run into CPU backend incorrectly and trigger this issue. Resolve it by installing MKL library from conda:\r\n    \r\n    ```bash\r\n    conda install mkl\r\n    conda install mkl-include\r\n    ```\r\n    \r\n    then clean build PyTorch\\*.\r\n\r\n- OSError: libmkl\\_intel\\_lp64.so.1: cannot open shared object file: No such file or directory\r\n\r\n    Wrong MKL library is used when multiple MKL libraries exist in system. Preload oneMKL by:\r\n    \r\n    ```bash\r\n    export LD_PRELOAD=${MKL_DPCPP_ROOT}/lib/intel64/libmkl_intel_lp64.so.1:${MKL_DPCPP_ROOT}/lib/intel64/libmkl_intel_ilp64.so.1:${MKL_DPCPP_ROOT}/lib/intel64/libmkl_sequential.so.1:${MKL_DPCPP_ROOT}/lib/intel64/libmkl_core.so.1:${MKL_DPCPP_ROOT}/lib/intel64/libmkl_sycl.so.1\r\n    ```\r\n    \r\n    If you continue seeing similar issues for other shared object files, add the corresponding files under ${MKL\\_DPCPP\\_ROOT}/lib/intel64/ by `LD_PRELOAD`. Note that the suffix of the libraries may change (e.g. from .1 to .2), if more than one oneMKL library is installed on the system.", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/81441463/reactions", "total_count": 12, "+1": 12, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/75767925", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/75767925/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/75767925/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.12.300", "id": 75767925, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4EhCB1", "tag_name": "v1.12.300", "target_commitish": "release/1.12", "name": "Intel\u00ae Extension for PyTorch* v1.12.300-cpu Release Notes", "draft": false, "prerelease": false, "created_at": "2022-08-30T12:04:58Z", "published_at": "2022-09-14T23:20:36Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/77902840", "id": 77902840, "node_id": "RA_kwDOD0MuUM4EpLP4", "name": "intel_extension_for_pytorch-1.12.300+cpu-cp310-cp310-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 42727693, "download_count": 11, "created_at": "2022-09-14T23:19:14Z", "updated_at": "2022-09-14T23:19:25Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.300/intel_extension_for_pytorch-1.12.300%2Bcpu-cp310-cp310-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/77902856", "id": 77902856, "node_id": "RA_kwDOD0MuUM4EpLQI", "name": "intel_extension_for_pytorch-1.12.300+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 42987046, "download_count": 1, "created_at": "2022-09-14T23:19:33Z", "updated_at": "2022-09-14T23:19:45Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.300/intel_extension_for_pytorch-1.12.300%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/77902860", "id": 77902860, "node_id": "RA_kwDOD0MuUM4EpLQM", "name": "intel_extension_for_pytorch-1.12.300+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 42993035, "download_count": 5, "created_at": "2022-09-14T23:19:45Z", "updated_at": "2022-09-14T23:19:56Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.300/intel_extension_for_pytorch-1.12.300%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/77902831", "id": 77902831, "node_id": "RA_kwDOD0MuUM4EpLPv", "name": "intel_extension_for_pytorch-1.12.300+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 38236368, "download_count": 2, "created_at": "2022-09-14T23:18:56Z", "updated_at": "2022-09-14T23:19:14Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.300/intel_extension_for_pytorch-1.12.300%2Bcpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/77902854", "id": 77902854, "node_id": "RA_kwDOD0MuUM4EpLQG", "name": "libintel-ext-pt-1.12.300+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 16226410, "download_count": 2, "created_at": "2022-09-14T23:19:25Z", "updated_at": "2022-09-14T23:19:29Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.300/libintel-ext-pt-1.12.300%2Bcpu.run"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/77902855", "id": 77902855, "node_id": "RA_kwDOD0MuUM4EpLQH", "name": "libintel-ext-pt-cxx11-abi-1.12.300+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 16289933, "download_count": 3, "created_at": "2022-09-14T23:19:29Z", "updated_at": "2022-09-14T23:19:33Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.300/libintel-ext-pt-cxx11-abi-1.12.300%2Bcpu.run"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.12.300", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.12.300", "body": "## Highlights\r\n\r\n- Optimize BF16 MHA fusion to avoid transpose overhead to boost BERT-* BF16 performance [#992](https://github.com/intel/intel-extension-for-pytorch/commit/7076524601f42a9b60402019af21b32782c2c203)\r\n- Remove 64bytes alignment constraint for FP32 and BF16 AddLayerNorm fusion [#992](https://github.com/intel/intel-extension-for-pytorch/commit/7076524601f42a9b60402019af21b32782c2c203)\r\n- Fix INT8 RetinaNet accuracy issue [#1032](https://github.com/intel/intel-extension-for-pytorch/commit/e0c719be8246041f8b7bc5feca9cf9c2f599210a)\r\n- Fix `Cat.out` issue that does not update the `out` tensor (#1053) [#1074](https://github.com/intel/intel-extension-for-pytorch/commit/4381f9126bbb65aab2daf034299c3bf3d307e6e2)\r\n\r\n**Full Changelog**: https://github.com/intel/intel-extension-for-pytorch/compare/v1.12.100...v1.12.300"}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/73607549", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/73607549/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/73607549/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.12.100", "id": 73607549, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4EYyl9", "tag_name": "v1.12.100", "target_commitish": "release/1.12", "name": "Intel\u00ae Extension for PyTorch* v1.12.100-cpu Release Notes", "draft": false, "prerelease": false, "created_at": "2022-08-04T06:11:05Z", "published_at": "2022-08-04T06:42:08Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640359", "id": 73640359, "node_id": "RA_kwDOD0MuUM4EY6mn", "name": "intel_extension_for_pytorch-1.12.100+cpu-cp310-cp310-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41312935, "download_count": 11, "created_at": "2022-08-04T06:17:18Z", "updated_at": "2022-08-04T06:17:35Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100%2Bcpu-cp310-cp310-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640325", "id": 73640325, "node_id": "RA_kwDOD0MuUM4EY6mF", "name": "intel_extension_for_pytorch-1.12.100+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41572406, "download_count": 4, "created_at": "2022-08-04T06:16:51Z", "updated_at": "2022-08-04T06:17:05Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640346", "id": 73640346, "node_id": "RA_kwDOD0MuUM4EY6ma", "name": "intel_extension_for_pytorch-1.12.100+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41578397, "download_count": 5, "created_at": "2022-08-04T06:17:05Z", "updated_at": "2022-08-04T06:17:12Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640354", "id": 73640354, "node_id": "RA_kwDOD0MuUM4EY6mi", "name": "intel_extension_for_pytorch-1.12.100+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 36821659, "download_count": 5, "created_at": "2022-08-04T06:17:12Z", "updated_at": "2022-08-04T06:17:18Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100%2Bcpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640412", "id": 73640412, "node_id": "RA_kwDOD0MuUM4EY6nc", "name": "intel_extension_for_pytorch-1.12.100-cp310-cp310-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41198040, "download_count": 3, "created_at": "2022-08-04T06:18:17Z", "updated_at": "2022-08-04T06:18:34Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100-cp310-cp310-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640368", "id": 73640368, "node_id": "RA_kwDOD0MuUM4EY6mw", "name": "intel_extension_for_pytorch-1.12.100-cp37-cp37m-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41457146, "download_count": 2, "created_at": "2022-08-04T06:17:35Z", "updated_at": "2022-08-04T06:18:00Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100-cp37-cp37m-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640393", "id": 73640393, "node_id": "RA_kwDOD0MuUM4EY6nJ", "name": "intel_extension_for_pytorch-1.12.100-cp38-cp38-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41455448, "download_count": 2, "created_at": "2022-08-04T06:18:00Z", "updated_at": "2022-08-04T06:18:10Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100-cp38-cp38-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640406", "id": 73640406, "node_id": "RA_kwDOD0MuUM4EY6nW", "name": "intel_extension_for_pytorch-1.12.100-cp39-cp39-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 36701526, "download_count": 3, "created_at": "2022-08-04T06:18:10Z", "updated_at": "2022-08-04T06:18:17Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/intel_extension_for_pytorch-1.12.100-cp39-cp39-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640422", "id": 73640422, "node_id": "RA_kwDOD0MuUM4EY6nm", "name": "libintel-ext-pt-1.12.100+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 14802211, "download_count": 7, "created_at": "2022-08-04T06:18:34Z", "updated_at": "2022-08-04T06:18:38Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/libintel-ext-pt-1.12.100%2Bcpu.run"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/73640425", "id": 73640425, "node_id": "RA_kwDOD0MuUM4EY6np", "name": "libintel-ext-pt-cxx11-abi-1.12.100+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 14867795, "download_count": 9, "created_at": "2022-08-04T06:18:38Z", "updated_at": "2022-08-04T06:18:41Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.100/libintel-ext-pt-cxx11-abi-1.12.100%2Bcpu.run"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.12.100", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.12.100", "body": "This is a patch release to fix the AVX2 issue that blocks running on non-AVX512 platforms."}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/70818797", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/70818797/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/70818797/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.12.0", "id": 70818797, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4EOJvt", "tag_name": "v1.12.0", "target_commitish": "master", "name": "Intel\u00ae Extension for PyTorch* v1.12.0-cpu Release Notes", "draft": false, "prerelease": false, "created_at": "2022-07-06T06:13:33Z", "published_at": "2022-07-06T06:44:08Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582424", "id": 70582424, "node_id": "RA_kwDOD0MuUM4ENQCY", "name": "intel_extension_for_pytorch-1.12.0+cpu-cp310-cp310-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41881537, "download_count": 7, "created_at": "2022-07-05T04:58:39Z", "updated_at": "2022-07-05T04:58:49Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0%2Bcpu-cp310-cp310-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582410", "id": 70582410, "node_id": "RA_kwDOD0MuUM4ENQCK", "name": "intel_extension_for_pytorch-1.12.0+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 42135119, "download_count": 4, "created_at": "2022-07-05T04:58:22Z", "updated_at": "2022-07-05T04:58:27Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582405", "id": 70582405, "node_id": "RA_kwDOD0MuUM4ENQCF", "name": "intel_extension_for_pytorch-1.12.0+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 42143163, "download_count": 3, "created_at": "2022-07-05T04:58:15Z", "updated_at": "2022-07-05T04:58:22Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582442", "id": 70582442, "node_id": "RA_kwDOD0MuUM4ENQCq", "name": "intel_extension_for_pytorch-1.12.0+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 37503279, "download_count": 3, "created_at": "2022-07-05T04:58:56Z", "updated_at": "2022-07-05T04:59:03Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0%2Bcpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582433", "id": 70582433, "node_id": "RA_kwDOD0MuUM4ENQCh", "name": "intel_extension_for_pytorch-1.12.0-cp310-cp310-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41780910, "download_count": 3, "created_at": "2022-07-05T04:58:49Z", "updated_at": "2022-07-05T04:58:56Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0-cp310-cp310-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582414", "id": 70582414, "node_id": "RA_kwDOD0MuUM4ENQCO", "name": "intel_extension_for_pytorch-1.12.0-cp37-cp37m-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 42037519, "download_count": 3, "created_at": "2022-07-05T04:58:27Z", "updated_at": "2022-07-05T04:58:39Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0-cp37-cp37m-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70588571", "id": 70588571, "node_id": "RA_kwDOD0MuUM4ENRib", "name": "intel_extension_for_pytorch-1.12.0-cp38-cp38-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 42045593, "download_count": 2, "created_at": "2022-07-05T06:27:03Z", "updated_at": "2022-07-05T06:27:10Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0-cp38-cp38-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582453", "id": 70582453, "node_id": "RA_kwDOD0MuUM4ENQC1", "name": "intel_extension_for_pytorch-1.12.0-cp39-cp39-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 37398940, "download_count": 3, "created_at": "2022-07-05T04:59:03Z", "updated_at": "2022-07-05T04:59:10Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/intel_extension_for_pytorch-1.12.0-cp39-cp39-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582994", "id": 70582994, "node_id": "RA_kwDOD0MuUM4ENQLS", "name": "libintel-ext-pt-1.12.0+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 15582932, "download_count": 6, "created_at": "2022-07-05T05:10:29Z", "updated_at": "2022-07-05T05:10:33Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/libintel-ext-pt-1.12.0%2Bcpu.run"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/70582998", "id": 70582998, "node_id": "RA_kwDOD0MuUM4ENQLW", "name": "libintel-ext-pt-cxx11-abi-1.12.0+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 15556308, "download_count": 3, "created_at": "2022-07-05T05:10:33Z", "updated_at": "2022-07-05T05:10:36Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.12.0/libintel-ext-pt-cxx11-abi-1.12.0%2Bcpu.run"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.12.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.12.0", "body": "We are excited to bring you the release of Intel\u00ae Extension for PyTorch* [1.12.0-cpu](https://github.com/pytorch/pytorch/releases/tag/v1.12.0), by tightly following PyTorch 1.12 release. In this release, we matured the automatic int8 quantization and made it a stable feature. We stabilized runtime extension and brought about a MultiStreamModule feature to further boost throughput in offline inference scenario. We also brought about various enhancements in operation and graph which are positive for the performance of broad set of workloads.\r\n\r\n- Automatic INT8 quantization became a stable feature baking into a well-tuned default quantization recipe, supporting both static and dynamic quantization and a wide range of calibration algorithms.\r\n- Runtime Extension, featured MultiStreamModule, became a stable feature, could further enhance throughput in offline inference scenario.\r\n- More optimizations in graph and operations to improve performance of broad set of models, examples include but not limited to wave2vec, T5, Albert etc.\r\n- Pre-built experimental binary with oneDNN Graph Compiler tuned on would deliver additional performance gain for Bert, Albert, Roberta in INT8 inference.\r\n\r\n## Highlights\r\n- Matured automatic INT8 quantization feature baking into a well-tuned default quantization recipe. We facilitated the user experience and provided a wide range of calibration algorithms like Histogram, MinMax, MovingAverageMinMax, etc. Meanwhile, We polished the static quantization with better flexibility and enabled dynamic quantization as well. Compared to the previous version, the brief changes are as follows. Refer to [tutorial page](features/int8.md) for more details.\r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.11.0-cpu</td>\r\n<td>v1.12.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\">\r\n\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n\r\n# Calibrate the model\r\nqconfig = ipex.quantization.QuantConf(qscheme=torch.per_tensor_affine)\r\nfor data in calibration_data_set:\r\n    with ipex.quantization.calibrate(qconfig):\r\n        model_to_be_calibrated(x)\r\nqconfig.save('qconfig.json')\r\n\r\n# Convert the model to jit model\r\nconf = ipex.quantization.QuantConf('qconfig.json')\r\nwith torch.no_grad():\r\n    traced_model = ipex.quantization.convert(model, conf, example_input)\r\n\r\n\r\n# Do inference \r\ny = traced_model(x)\r\n```\r\n</td>\r\n<td valign=\"top\">\r\n\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n\r\n# Calibrate the model\r\nqconfig = ipex.quantization.default_static_qconfig # Histogram calibration algorithm and \r\ncalibrated_model = ipex.quantization.prepare(model_to_be_calibrated, qconfig, example_inputs=example_inputs)\r\nfor data in calibration_data_set:\r\n    calibrated_model(data)\r\n\r\n\r\n# Convert the model to jit model\r\nquantized_model = ipex.quantization.convert(calibrated_model)\r\nwith torch.no_grad():\r\n    traced_model = torch.jit.trace(quantized_model, example_input)\r\n    traced_model = torch.jit.freeze(traced_model)\r\n\r\n# Do inference \r\ny = traced_model(x)\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- Runtime Extension, featured MultiStreamModule, became a stable feature. In this release, we enhanced the heuristic rule to further enhance throughput in offline inference scenario. Meanwhile, we also provide the `ipex.cpu.runtime.MultiStreamModuleHint` to custom how to split the input into streams and concat the output for each steam.\r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.11.0-cpu</td>\r\n<td>v1.12.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\">\r\n\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n\r\n# Create CPU pool\r\ncpu_pool = ipex.cpu.runtime.CPUPool(node_id=0)\r\n\r\n# Create multi-stream model\r\nmulti_Stream_model = ipex.cpu.runtime.MultiStreamModule(model, num_streams=2, cpu_pool=cpu_pool)\r\n```\r\n</td>\r\n<td valign=\"top\">\r\n\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n\r\n# Create CPU pool\r\ncpu_pool = ipex.cpu.runtime.CPUPool(node_id=0)\r\n\r\n# Optional\r\nmulti_stream_input_hint = ipex.cpu.runtime.MultiStreamModuleHint(0)\r\nmulti_stream_output_hint = ipex.cpu.runtime.MultiStreamModuleHint(0)\r\n\r\n# Create multi-stream model\r\nmulti_Stream_model = ipex.cpu.runtime.MultiStreamModule(model, num_streams=2, cpu_pool=cpu_pool,\r\n  multi_stream_input_hint,   # optional\r\n  multi_stream_output_hint ) # optional\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- Polished the `ipex.optimize` to accept the input shape information which would conclude the optimal memory layout for better kernel efficiency.\r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.11.0-cpu</td>\r\n<td>v1.12.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td valign=\"top\">\r\n\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nmodel = ...\r\nmodel.load_state_dict(torch.load(PATH))\r\nmodel.eval()\r\noptimized_model = ipex.optimize(model, dtype=torch.bfloat16)\r\n```\r\n</td>\r\n<td valign=\"top\">\r\n\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nmodel = ...\r\nmodel.load_state_dict(torch.load(PATH))\r\nmodel.eval()\r\noptimized_model = ipex.optimize(model, dtype=torch.bfloat16, sample_input=input)\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- Provided a pre-built experimental binary with oneDNN Graph Compiler turned on, which would deliver additional performance gain for Bert, Albert, and Roberta in INT8 inference. \r\n\r\n- Provided more optimizations in graph and operations\r\n  - Fuse Adam to improve training performance [#822](https://github.com/intel/intel-extension-for-pytorch/commit/d3f714e54dc8946675259ea7a445b26a2460b523)\r\n  - Enable Normalization operators to support channels-last 3D [#642](https://github.com/intel/intel-extension-for-pytorch/commit/ae268ac1760d598a29584de5c99bfba46c6554ae)\r\n  - Support Deconv3D to serve most models and implement most fusions like Conv\r\n  - Enable LSTM to support static and dynamic quantization [#692](https://github.com/intel/intel-extension-for-pytorch/commit/2bf8dba0c380a26bbb385e253adbfaa2a033a785)\r\n  - Enable Linear to support dynamic quantization [#787](https://github.com/intel/intel-extension-for-pytorch/commit/ff231fb55e33c37126a0ef7f0e739cd750d1ef6c)\r\n  - Fusions.\r\n    - Fuse `Add` + `Swish` to accelerate FSI Riskful model [#551](https://github.com/intel/intel-extension-for-pytorch/commit/cc855ff2bafd245413a6111f3d21244d0bcbb6f6)\r\n    - Fuse `Conv` + `LeakyReLU` [#589](https://github.com/intel/intel-extension-for-pytorch/commit/dc6ed1a5967c644b03874fd1f8a503f0b80be6bd)\r\n    - Fuse `BMM` + `Add` [#407](https://github.com/intel/intel-extension-for-pytorch/commit/d1379aa565cc84b4a61b537ba2c9a046b7652f1a)\r\n    - Fuse `Concat` + `BN` + `ReLU` [#647](https://github.com/intel/intel-extension-for-pytorch/commit/cad3f82f6b7efed0c08b2f0c11117a4720f58df4)\r\n    - Optimize `Convolution1D` to support channels last memory layout and fuse `GeLU` as its post operation. [#657](https://github.com/intel/intel-extension-for-pytorch/commit/a0c063bdf4fd1a7e66f8a23750ac0c2fe471a559)\r\n    - Fuse `Einsum` + `Add` to boost Alphafold2 [#674](https://github.com/intel/intel-extension-for-pytorch/commit/3094f346a67c81ad858ad2a80900fab4c3b4f4e9)\r\n    - Fuse `Linear` + `Tanh` [#711](https://github.com/intel/intel-extension-for-pytorch/commit/b24cc530b1fd29cb161a76317891e361453333c9)\r\n \r\n### Known Issues\r\n- `RuntimeError: Overflow when unpacking long` when a tensor's min max value exceeds int range while performing int8 calibration. Please customize QConfig to use min-max calibration method.\r\n- Calibrating with quantize_per_tensor, when benchmarking with 1 OpenMP\\* thread, results might be incorrect with large tensors (find more detailed info [here](https://github.com/pytorch/pytorch/issues/80501). Editing your code following the pseudocode below can workaround this issue, if you do need to explicitly set OMP_NUM_THREAEDS=1 for benchmarking. However, there could be a performance regression if oneDNN graph compiler prototype feature is utilized.\r\n\r\n  Workaround pseudocode:\r\n  ```\r\n  # perform convert/trace/freeze with omp_num_threads > 1(N)\r\n  torch.set_num_threads(N)\r\n  prepared_model = prepare(model, input)\r\n  converted_model = convert(prepared_model)\r\n  traced_model = torch.jit.trace(converted_model, input)\r\n  freezed_model = torch.jit.freeze(traced_model)\r\n  # run freezed model to apply optimization pass\r\n  freezed_model(input)\r\n\r\n  # benchmarking with omp_num_threads = 1\r\n  torch.set_num_threads(1)\r\n  run_benchmark(freezed_model, input)\r\n  ```\r\n- Low performance with INT8 support for dynamic shapes\r\n  The support for dynamic shapes in Intel\u00ae Extension for PyTorch\\* INT8 integration is still work in progress. When the input shapes are dynamic, for example inputs of variable image sizes in an object detection task or of variable sequence lengths in NLP tasks, the Intel\u00ae Extension for PyTorch\\* INT8 path may slow down the model inference. In this case, use stock PyTorch INT8 functionality.\r\n  **Note**: Using Runtime Extension feature if batch size cannot be divided by number of streams, because mini batch size on each stream are not equivalent, scripts run into this issues.\r\n- BF16 AMP(auto-mixed-precision) runs abnormally with the extension on the AVX2-only machine if the topology contains `Conv`, `Matmul`, `Linear`, and `BatchNormalization`\r\n- Runtime extension of MultiStreamModule doesn't support DLRM inference, since the input of DLRM (EmbeddingBag specifically) can't be simplely batch split.\r\n- Runtime extension of MultiStreamModule has poor performance of RNNT Inference comparing with native throughput mode. Only part of the RNNT models (joint_net specifically) can be jit traced into graph. However, in one batch inference, `joint_net` is invoked multi times. It increases the overhead of MultiStreamModule as input batch split, thread synchronization and output concat.\r\n- Incorrect Conv and Linear result if the number of OMP threads is changed at runtime\r\n  The oneDNN memory layout depends on the number of OMP threads, which requires the caller to detect the changes for the # of OMP threads while this release has not implemented it yet.\r\n- Low throughput with DLRM FP32 Train\r\n  A 'Sparse Add' [PR](https://github.com/pytorch/pytorch/pull/23057) is pending on review. The issue will be fixed when the PR is merged.\r\n- If inference is done with a custom function, `conv+bn` folding feature of the `ipex.optimize()` function doesn't work.\r\n  ```\r\n  import torch\r\n  import intel_pytorch_extension as ipex\r\n  class Module(torch.nn.Module):\r\n      def __init__(self):\r\n          super(Module, self).__init__()\r\n          self.conv = torch.nn.Conv2d(1, 10, 5, 1)\r\n          self.bn = torch.nn.BatchNorm2d(10)\r\n          self.relu = torch.nn.ReLU()\r\n      def forward(self, x):\r\n          x = self.conv(x)\r\n          x = self.bn(x)\r\n          x = self.relu(x)\r\n          return x\r\n      def inference(self, x):\r\n          return self.forward(x)\r\n  if __name__ == '__main__':\r\n      m = Module()\r\n      m.eval()\r\n      m = ipex.optimize(m, dtype=torch.float32, level=\"O0\")\r\n      d = torch.rand(1, 1, 112, 112)\r\n      with torch.no_grad():\r\n        m.inference(d)\r\n  ```\r\n  This is a PyTorch FX limitation. You can avoid this error by calling `m = ipex.optimize(m, level=\"O0\")`, which doesn't apply ipex optimization, or disable `conv+bn` folding by calling `m = ipex.optimize(m, level=\"O1\", conv_bn_folding=False)`.", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/70818797/reactions", "total_count": 4, "+1": 4, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/67058105", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/67058105/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/67058105/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.11.200", "id": 67058105, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4D_zm5", "tag_name": "v1.11.200", "target_commitish": "release/1.11", "name": "Intel\u00ae Extension for PyTorch* v1.11.200-cpu Release Notes", "draft": false, "prerelease": false, "created_at": "2022-05-19T08:31:57Z", "published_at": "2022-05-19T10:01:43Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65935364", "id": 65935364, "node_id": "RA_kwDOD0MuUM4D7hgE", "name": "intel_extension_for_pytorch-1.11.200+cpu-cp310-cp310-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 40979331, "download_count": 16, "created_at": "2022-05-18T22:06:16Z", "updated_at": "2022-05-18T22:06:37Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200%2Bcpu-cp310-cp310-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65893954", "id": 65893954, "node_id": "RA_kwDOD0MuUM4D7XZC", "name": "intel_extension_for_pytorch-1.11.200+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41098613, "download_count": 5, "created_at": "2022-05-18T14:16:34Z", "updated_at": "2022-05-18T14:16:58Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65893961", "id": 65893961, "node_id": "RA_kwDOD0MuUM4D7XZJ", "name": "intel_extension_for_pytorch-1.11.200+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41132690, "download_count": 6, "created_at": "2022-05-18T14:16:46Z", "updated_at": "2022-05-18T14:17:04Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65894035", "id": 65894035, "node_id": "RA_kwDOD0MuUM4D7XaT", "name": "intel_extension_for_pytorch-1.11.200+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 36300659, "download_count": 9, "created_at": "2022-05-18T14:17:30Z", "updated_at": "2022-05-18T14:17:42Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200%2Bcpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65935419", "id": 65935419, "node_id": "RA_kwDOD0MuUM4D7hg7", "name": "intel_extension_for_pytorch-1.11.200-cp310-cp310-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 40859961, "download_count": 2, "created_at": "2022-05-18T22:07:00Z", "updated_at": "2022-05-18T22:07:14Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200-cp310-cp310-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65894010", "id": 65894010, "node_id": "RA_kwDOD0MuUM4D7XZ6", "name": "intel_extension_for_pytorch-1.11.200-cp37-cp37m-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 40979645, "download_count": 2, "created_at": "2022-05-18T14:17:17Z", "updated_at": "2022-05-18T14:17:30Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200-cp37-cp37m-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65893992", "id": 65893992, "node_id": "RA_kwDOD0MuUM4D7XZo", "name": "intel_extension_for_pytorch-1.11.200-cp38-cp38-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41016651, "download_count": 2, "created_at": "2022-05-18T14:17:04Z", "updated_at": "2022-05-18T14:17:17Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200-cp38-cp38-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65894048", "id": 65894048, "node_id": "RA_kwDOD0MuUM4D7Xag", "name": "intel_extension_for_pytorch-1.11.200-cp39-cp39-manylinux2014_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 36176709, "download_count": 3, "created_at": "2022-05-18T14:17:42Z", "updated_at": "2022-05-18T14:17:54Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/intel_extension_for_pytorch-1.11.200-cp39-cp39-manylinux2014_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65894068", "id": 65894068, "node_id": "RA_kwDOD0MuUM4D7Xa0", "name": "libintel-ext-pt-cxx11-abi-shared-with-deps-1.11.200+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 14101301, "download_count": 5, "created_at": "2022-05-18T14:18:02Z", "updated_at": "2022-05-18T14:18:11Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/libintel-ext-pt-cxx11-abi-shared-with-deps-1.11.200%2Bcpu.run"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/65894061", "id": 65894061, "node_id": "RA_kwDOD0MuUM4D7Xat", "name": "libintel-ext-pt-shared-with-deps-1.11.200+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 14313198, "download_count": 7, "created_at": "2022-05-18T14:17:54Z", "updated_at": "2022-05-18T14:18:02Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.200/libintel-ext-pt-shared-with-deps-1.11.200%2Bcpu.run"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.11.200", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.11.200", "body": "## Highlights\r\n\r\n- Enable more fused operators to accelerate particular models.\r\n  - Fuse `Convolution` and `LeakyReLU` ([#648](https://github.com/intel/intel-extension-for-pytorch/commit/d7603133f37375b3aba7bf744f1095b923ba979e))\r\n  - Support [`torch.einsum`](https://pytorch.org/docs/stable/generated/torch.einsum.html) and fuse it with `add` ([#684](https://github.com/intel/intel-extension-for-pytorch/commit/b66d6d8d0c743db21e534d13be3ee75951a3771d))\r\n  - Fuse `Linear` and `Tanh` ([#685](https://github.com/intel/intel-extension-for-pytorch/commit/f0f2bae96162747ed2a0002b274fe7226a8eb200))\r\n- In addition to the existing installation methods, this release provides Docker installation from [DockerHub](https://hub.docker.com/).\r\n- Provide the [evaluation wheel packages](https://intel.github.io/intel-extension-for-pytorch/1.11.200/tutorials/installation.html#installation_onednn_graph_compiler) that could boost performance for selective topologies on top of oneDNN graph compiler prototype feature.\r\n***NOTE***: This is still at the early development stage and not fully mature yet, but feel free to reach out through GitHub tickets if you have any suggestions.\r\n\r\n**Full Changelog**: https://github.com/intel/intel-extension-for-pytorch/compare/v1.11.0...v1.11.200"}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/61863910", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/61863910/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/61863910/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.11.0", "id": 61863910, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4Dr_fm", "tag_name": "v1.11.0", "target_commitish": "release/1.11", "name": "Intel\u00ae Extension for PyTorch* v1.11.0-cpu Release Notes", "draft": false, "prerelease": false, "created_at": "2022-03-16T06:01:03Z", "published_at": "2022-03-16T06:15:45Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/59548572", "id": 59548572, "node_id": "RA_kwDOD0MuUM4DjKOc", "name": "intel_extension_for_pytorch-1.11.0+cpu-cp310-cp310-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41161081, "download_count": 5, "created_at": "2022-03-15T11:23:05Z", "updated_at": "2022-03-15T11:23:23Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.0/intel_extension_for_pytorch-1.11.0%2Bcpu-cp310-cp310-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/59548319", "id": 59548319, "node_id": "RA_kwDOD0MuUM4DjKKf", "name": "intel_extension_for_pytorch-1.11.0+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41280332, "download_count": 6, "created_at": "2022-03-15T11:18:54Z", "updated_at": "2022-03-15T11:19:13Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.0/intel_extension_for_pytorch-1.11.0%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/59548362", "id": 59548362, "node_id": "RA_kwDOD0MuUM4DjKLK", "name": "intel_extension_for_pytorch-1.11.0+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 41314299, "download_count": 3, "created_at": "2022-03-15T11:20:03Z", "updated_at": "2022-03-15T11:20:20Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.0/intel_extension_for_pytorch-1.11.0%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/59548389", "id": 59548389, "node_id": "RA_kwDOD0MuUM4DjKLl", "name": "intel_extension_for_pytorch-1.11.0+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 36482272, "download_count": 3, "created_at": "2022-03-15T11:20:34Z", "updated_at": "2022-03-15T11:20:50Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.0/intel_extension_for_pytorch-1.11.0%2Bcpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/59548651", "id": 59548651, "node_id": "RA_kwDOD0MuUM4DjKPr", "name": "libintel-ext-pt-1.11.0+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 14359119, "download_count": 5, "created_at": "2022-03-15T11:23:35Z", "updated_at": "2022-03-15T11:23:41Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.0/libintel-ext-pt-1.11.0%2Bcpu.run"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/59548669", "id": 59548669, "node_id": "RA_kwDOD0MuUM4DjKP9", "name": "libintel-ext-pt-cxx11-abi-1.11.0+cpu.run", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 14141073, "download_count": 3, "created_at": "2022-03-15T11:23:50Z", "updated_at": "2022-03-15T11:23:57Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.11.0/libintel-ext-pt-cxx11-abi-1.11.0%2Bcpu.run"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.11.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.11.0", "body": "We are excited to announce Intel\u00ae Extension for PyTorch* 1.11.0-cpu release by tightly following PyTorch 1.11 release. Along with extension 1.11, we focused on continually improving OOB user experience and performance. Highlights include:\r\n\r\n* Support a single binary with runtime dynamic dispatch based on AVX2/AVX512 hardware ISA detection\r\n* Support install binary from `pip` with package name only (without the need of specifying the URL)\r\n* Provide the C++ SDK installation to facilitate ease of C++ app development and deployment\r\n* Add more optimizations, including graph fusions for speeding up Transformer-based models and CNN, etc\r\n* Reduce the binary size for both the PIP wheel and C++ SDK (2X to 5X reduction from the previous version)\r\n\r\n## Highlights\r\n- Combine the AVX2 and AVX512 binary as a single binary and automatically dispatch to different implementations based on hardware ISA detection at runtime. The typical case is to serve the data center that mixtures AVX2-only and AVX512 platforms. It does not need to deploy the different ISA binary now compared to the previous version\r\n\r\n    ***NOTE***:  The extension uses the oneDNN library as the backend. However, the BF16 and INT8 operator sets and features are different between AVX2 and AVX512. Please refer to [oneDNN document](https://oneapi-src.github.io/oneDNN/dev_guide_int8_computations.html#processors-with-the-intel-avx2-or-intel-avx-512-support) for more details. \r\n    > When one input is of type u8, and the other one is of type s8, oneDNN assumes that it is the user\u2019s responsibility to choose the quantization parameters so that no overflow/saturation occurs. For instance, a user can use u7 [0, 127] instead of u8 for the unsigned input, or s7 [-64, 63] instead of the s8 one. It is worth mentioning that this is required only when the Intel AVX2 or Intel AVX512 Instruction Set is used.\r\n\r\n- The extension wheel packages have been uploaded to [pypi.org](https://pypi.org/project/intel-extension-for-pytorch/). The user could directly install the extension by `pip/pip3` without explicitly specifying the binary location URL.\r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.10.100-cpu</td>\r\n<td>v1.11.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td>\r\n\r\n```python\r\npython -m pip install intel_extension_for_pytorch==1.10.100 -f https://software.intel.com/ipex-whl-stable\r\n```\r\n</td>\r\n<td>\r\n\r\n```python\r\npip install intel_extension_for_pytorch\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- Compared to the previous version, this release provides a dedicated installation file for the C++ SDK. The installation file automatically detects the PyTorch C++ SDK location and installs the extension C++ SDK files to the PyTorch C++ SDK. The user does not need to manually add the extension C++ SDK source files and CMake to the PyTorch SDK. In addition to that, the installation file reduces the C++ SDK binary size from ~220MB to ~13.5MB. \r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.10.100-cpu</td>\r\n<td>v1.11.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td>\r\n\r\n```python\r\nintel-ext-pt-cpu-libtorch-shared-with-deps-1.10.0+cpu.zip (220M)\r\nintel-ext-pt-cpu-libtorch-cxx11-abi-shared-with-deps-1.10.0+cpu.zip (224M)\r\n```\r\n</td>\r\n<td>\r\n\r\n```python\r\nlibintel-ext-pt-1.11.0+cpu.run (13.7M)\r\nlibintel-ext-pt-cxx11-abi-1.11.0+cpu.run (13.5M)\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- Add more optimizations, including more custom operators and fusions.\r\n\r\n    - Fuse the QKV linear operators as a single Linear to accelerate the Transformer*(BERT-*) encoder part  - [#278](https://github.com/intel/intel-extension-for-pytorch/commit/0f27c269cae0f902973412dc39c9a7aae940e07b).\r\n    - Remove Multi-Head-Attention fusion limitations to support the 64bytes unaligned tensor shape. [#531](https://github.com/intel/intel-extension-for-pytorch/commit/dbb10fedb00c6ead0f5b48252146ae9d005a0fad)\r\n    - Fold the binary operator to Convolution and Linear operator to reduce computation. [#432](https://github.com/intel/intel-extension-for-pytorch/commit/564588561fa5d45b8b63e490336d151ff1fc9cbc) [#438](https://github.com/intel/intel-extension-for-pytorch/commit/b4e7dacf08acd849cecf8d143a11dc4581a3857f) [#602](https://github.com/intel/intel-extension-for-pytorch/commit/74aa21262938b923d3ed1e6929e7d2b629b3ff27)\r\n    - Replace the outplace operators with their corresponding in-place version to reduce memory footprint. The extension currently supports the operators including `sliu`, `sigmoid`, `tanh`, `hardsigmoid`, `hardswish`, `relu6`, `relu`, `selu`, `softmax`. [#524](https://github.com/intel/intel-extension-for-pytorch/commit/38647677e8186a235769ea519f4db65925eca33c)\r\n    - Fuse the Concat + BN + ReLU as a single operator. [#452](https://github.com/intel/intel-extension-for-pytorch/commit/275ff503aea780a6b741f04db5323d9529ee1081)\r\n    - Optimize Conv3D for both imperative and JIT by enabling NHWC and pre-packing the weight. [#425](https://github.com/intel/intel-extension-for-pytorch/commit/ae33faf62bb63b204b0ee63acb8e29e24f6076f3)\r\n\r\n- Reduce the binary size. C++ SDK is reduced from ~220MB to ~13.5MB while the wheel packaged is reduced from ~100MB to ~40MB.\r\n\r\n- Update oneDNN and oneDNN graph to [2.5.2](https://github.com/oneapi-src/oneDNN/releases/tag/v2.5.2) and [0.4.2](https://github.com/oneapi-src/oneDNN/releases/tag/graph-v0.4.2) respectively.\r\n\r\n## Known Issues\r\n- BF16 AMP(auto-mixed-precision) runs abnormally with the extension on the AVX2-only machine if the topology contains `Conv`, `Matmul`, `Linear`, and `BatchNormalization`\r\n\r\n- Runtime extension does not support the scenario that the BS is not divisible by the stream number\r\n\r\n- Incorrect Conv and Linear result if the number of OMP threads is changed at runtime\r\n\r\n    The oneDNN memory layout depends on the number of OMP threads, which requires the caller to detect the changes for the # of OMP threads while this release has not implemented it yet.\r\n\r\n- INT8 performance of EfficientNet and DenseNet with the extension is slower than that of FP32\r\n\r\n- Low performance with INT8 support for dynamic shapes\r\n\r\n    The support for dynamic shapes in Intel\u00ae Extension for PyTorch* INT8 integration is still working in progress. For the use cases where the input shapes are dynamic, for example, inputs of variable image sizes in an object detection task or of variable sequence lengths in NLP tasks, the Intel\u00ae Extension for PyTorch* INT8 path may slow down the model inference. In this case, please utilize stock PyTorch INT8 functionality.\r\n\r\n- Low throughput with DLRM FP32 Train\r\n\r\n    A \u2018Sparse Add\u2019 [PR](https://github.com/pytorch/pytorch/pull/23057) is pending on review. The issue will be fixed when the PR is merged.\r\n\r\n- If the inference is done with a custom function, conv+bn folding feature of the `ipex.optimize()` function doesn\u2019t work.\r\n\r\n    ```python\r\n    import torch\r\n    import intel_pytorch_extension as ipex\r\n    \r\n    class Module(torch.nn.Module):\r\n        def __init__(self):\r\n            super(Module, self).__init__()\r\n            self.conv = torch.nn.Conv2d(1, 10, 5, 1)\r\n            self.bn = torch.nn.BatchNorm2d(10)\r\n            self.relu = torch.nn.ReLU()\r\n    \r\n        def forward(self, x):\r\n            x = self.conv(x)\r\n            x = self.bn(x)\r\n            x = self.relu(x)\r\n            return x\r\n    \r\n        def inference(self, x):\r\n            return self.forward(x)\r\n    \r\n    if __name__ == '__main__':\r\n        m = Module()\r\n        m.eval()\r\n        m = ipex.optimize(m, dtype=torch.float32, level=\"O0\")\r\n        d = torch.rand(1, 1, 112, 112)\r\n        with torch.no_grad():\r\n          m.inference(d)\r\n    ```\r\n    This is PyTorch FX limitation, user can avoid this error by calling `m = ipex.optimize(m, level=\"O0\")`, which doesn't apply the extension optimization, or disable `conv+bn` folding by calling `m = ipex.optimize(m, level=\"O1\", conv_bn_folding=False)`.\r\n\r\n## What's Changed\r\n**Full Changelog**: https://github.com/intel/intel-extension-for-pytorch/compare/v1.10.100...v1.11.0", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/61863910/reactions", "total_count": 3, "+1": 1, "-1": 0, "laugh": 1, "hooray": 1, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/55639283", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/55639283/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/55639283/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.10.100", "id": 55639283, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4DUPzz", "tag_name": "v1.10.100", "target_commitish": "release/1.10", "name": "Intel\u00ae Extension for PyTorch* v1.10.100-cpu Release Notes", "draft": false, "prerelease": false, "created_at": "2021-12-15T06:20:39Z", "published_at": "2021-12-20T13:37:47Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/52167838", "id": 52167838, "node_id": "RA_kwDOD0MuUM4DHASe", "name": "intel_extension_for_pytorch-1.10.100+cpu-cp36-cp36m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 106838653, "download_count": 7, "created_at": "2021-12-20T02:48:42Z", "updated_at": "2021-12-20T02:49:02Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.100/intel_extension_for_pytorch-1.10.100%2Bcpu-cp36-cp36m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/52167856", "id": 52167856, "node_id": "RA_kwDOD0MuUM4DHASw", "name": "intel_extension_for_pytorch-1.10.100+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 106840394, "download_count": 12, "created_at": "2021-12-20T02:49:14Z", "updated_at": "2021-12-20T02:49:24Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.100/intel_extension_for_pytorch-1.10.100%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/52167866", "id": 52167866, "node_id": "RA_kwDOD0MuUM4DHAS6", "name": "intel_extension_for_pytorch-1.10.100+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 106853876, "download_count": 8, "created_at": "2021-12-20T02:49:34Z", "updated_at": "2021-12-20T02:49:45Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.100/intel_extension_for_pytorch-1.10.100%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/52167889", "id": 52167889, "node_id": "RA_kwDOD0MuUM4DHATR", "name": "intel_extension_for_pytorch-1.10.100+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 103133376, "download_count": 12, "created_at": "2021-12-20T02:49:55Z", "updated_at": "2021-12-20T02:50:04Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.100/intel_extension_for_pytorch-1.10.100%2Bcpu-cp39-cp39-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/52167961", "id": 52167961, "node_id": "RA_kwDOD0MuUM4DHAUZ", "name": "libtorch-cxx11-abi-shared-with-deps-1.10.0+cpu-intel-ext-pt-cpu-1.10.100.zip", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/x-zip-compressed", "state": "uploaded", "size": 234931494, "download_count": 13, "created_at": "2021-12-20T02:50:59Z", "updated_at": "2021-12-20T02:51:23Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.100/libtorch-cxx11-abi-shared-with-deps-1.10.0%2Bcpu-intel-ext-pt-cpu-1.10.100.zip"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/52167899", "id": 52167899, "node_id": "RA_kwDOD0MuUM4DHATb", "name": "libtorch-shared-with-deps-1.10.0+cpu-intel-ext-pt-cpu-1.10.100.zip", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/x-zip-compressed", "state": "uploaded", "size": 229745831, "download_count": 4, "created_at": "2021-12-20T02:50:17Z", "updated_at": "2021-12-20T02:50:37Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.100/libtorch-shared-with-deps-1.10.0%2Bcpu-intel-ext-pt-cpu-1.10.100.zip"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.10.100", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.10.100", "body": "This release is meant to fix the following issues:\r\n\r\n- Resolve the issue that the PyTorch Tensor Expression(TE) did not work after importing the extension.\r\n- Wrap the BatchNorm(BN) as another operator to break the TE's BN-related fusions. Because the BatchNorm performance of PyTorch Tensor Expression can not achieve the same performance as PyTorch ATen BN. \r\n- Update the [documentation](https://intel.github.io/intel-extension-for-pytorch/)\r\n    - Fix the INT8 quantization example issue #205 \r\n    - Polish the installation guide\r\n\r\n**Full Changelog**: https://github.com/intel/intel-extension-for-pytorch/compare/v1.10.0...v1.10.100", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/55639283/reactions", "total_count": 2, "+1": 2, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/54213213", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/54213213/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/54213213/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.10.0", "id": 54213213, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOD0MuUM4DOzpd", "tag_name": "v1.10.0", "target_commitish": "release/1.10", "name": "v1.10.0", "draft": false, "prerelease": false, "created_at": "2021-12-02T01:02:08Z", "published_at": "2021-12-02T01:16:17Z", "assets": [{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/50746891", "id": 50746891, "node_id": "RA_kwDOD0MuUM4DBlYL", "name": "intel-ext-pt-cpu-libtorch-cxx11-abi-shared-with-deps-1.10.0+cpu.zip", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/x-zip-compressed", "state": "uploaded", "size": 234930027, "download_count": 2, "created_at": "2021-12-01T15:24:00Z", "updated_at": "2021-12-01T15:25:33Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.0/intel-ext-pt-cpu-libtorch-cxx11-abi-shared-with-deps-1.10.0%2Bcpu.zip"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/50745974", "id": 50745974, "node_id": "RA_kwDOD0MuUM4DBlJ2", "name": "intel-ext-pt-cpu-libtorch-shared-with-deps-1.10.0+cpu.zip", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/x-zip-compressed", "state": "uploaded", "size": 230164108, "download_count": 0, "created_at": "2021-12-01T15:13:11Z", "updated_at": "2021-12-01T15:21:34Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.0/intel-ext-pt-cpu-libtorch-shared-with-deps-1.10.0%2Bcpu.zip"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/50743140", "id": 50743140, "node_id": "RA_kwDOD0MuUM4DBkdk", "name": "intel_extension_for_pytorch-1.10.0+cpu-cp36-cp36m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 106837723, "download_count": 3, "created_at": "2021-12-01T14:38:13Z", "updated_at": "2021-12-01T14:40:37Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.0/intel_extension_for_pytorch-1.10.0%2Bcpu-cp36-cp36m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/50743801", "id": 50743801, "node_id": "RA_kwDOD0MuUM4DBkn5", "name": "intel_extension_for_pytorch-1.10.0+cpu-cp37-cp37m-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 106839349, "download_count": 34, "created_at": "2021-12-01T14:44:36Z", "updated_at": "2021-12-01T14:49:59Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.0/intel_extension_for_pytorch-1.10.0%2Bcpu-cp37-cp37m-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/50744296", "id": 50744296, "node_id": "RA_kwDOD0MuUM4DBkvo", "name": "intel_extension_for_pytorch-1.10.0+cpu-cp38-cp38-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 106852399, "download_count": 3, "created_at": "2021-12-01T14:50:18Z", "updated_at": "2021-12-01T14:52:43Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.0/intel_extension_for_pytorch-1.10.0%2Bcpu-cp38-cp38-linux_x86_64.whl"}, {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/assets/50745293", "id": 50745293, "node_id": "RA_kwDOD0MuUM4DBk_N", "name": "intel_extension_for_pytorch-1.10.0+cpu-cp39-cp39-linux_x86_64.whl", "label": null, "uploader": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "content_type": "application/octet-stream", "state": "uploaded", "size": 103132270, "download_count": 0, "created_at": "2021-12-01T15:02:23Z", "updated_at": "2021-12-01T15:11:46Z", "browser_download_url": "https://github.com/intel/intel-extension-for-pytorch/releases/download/v1.10.0/intel_extension_for_pytorch-1.10.0%2Bcpu-cp39-cp39-linux_x86_64.whl"}], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.10.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.10.0", "body": "# Intel\u00ae Extension for PyTorch* v1.10.0-cpu Release Notes\r\n\r\nThe Intel\u00ae Extension for PyTorch* 1.10 is on top of PyTorch 1.10. In this release, we polished the front-end APIs. The APIs are more simple, stable, and straightforward now. According to the PyTorch community recommendation, we changed the underhood device from `XPU` to `CPU`. With this change, the model and tensor do not need to be converted to the extension device to get a performance improvement. It simplifies the model changes.\r\n\r\nBesides that, we continuously optimize the Transformer* and CNN models by fusing more operators and applying NHWC. We measured the 1.10 performance on Torchvison and HugginFace. As expected, 1.10 can speed up the two model zones. In addition, 1.10 releases the C++ SDK to facilitate PyTorch deployment with the extension.\r\n\r\n## Highlights\r\n\r\n- Change the package name to `intel_extension_for_pytorch` while the original package name is `intel_pytorch_extension`. This change targets to avoid any potential legal issues.\r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.9.0-cpu</td>\r\n<td>v1.10.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td>\r\n\r\n```python\r\nimport intel_pytorch_extension as ipex\r\n```\r\n</td>\r\n<td>\r\n\r\n```python\r\nimport intel_extension_for_pytorch as ipex\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- The underhood device is changed from the extension-specific device(`XPU`) to the standard CPU device which aligns with PyTorch CPU device design regardless of the dispatch mechanism and operator register mechanism. The model does not need to be converted to the extension device explicitly.\r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.9.0-cpu</td>\r\n<td>v1.10.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td>\r\n\r\n```python\r\nimport torch\r\nimport torchvision.models as models\r\n\r\n# Import the extension\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nresnet18 = models.resnet18(pretrained = True)\r\n\r\n# Explicitly convert the model to the extension device\r\nresnet18_xpu = resnet18.to(ipex.DEVICE)\r\n```\r\n</td>\r\n<td>\r\n\r\n```python\r\nimport torch\r\nimport torchvision.models as models\r\n\r\n# Import the extension\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nresnet18 = models.resnet18(pretrained = True)\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- Compared to 1.9.0, 1.10.0 follows PyTorch AMP API(`torch.cpu.amp`) to support auto-mixed-precision. `torch.cpu.amp` provides convenience for auto data type conversion at runtime. `torch.cpu.amp` supports `torch.bfloat16` now to boost the performance on Intel CPU what has BFloat16 instructions.\r\n\r\n```python\r\nimport torch\r\nclass SimpleNet(torch.nn.Module):\r\n    def __init__(self):\r\n        super(SimpleNet, self).__init__()\r\n        self.conv = torch.nn.Conv2d(64, 128, (3, 3), stride=(2, 2), padding=(1, 1), bias=False)\r\n\r\n    def forward(self, x):\r\n        return self.conv(x)\r\n```\r\n\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.9.0-cpu</td>\r\n<td>v1.10.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td>\r\n\r\n```python\r\n# Import the extension\r\nimport intel_pytorch_extension as ipex\r\n\r\n# Automatically mix precision\r\nipex.enable_auto_mixed_precision(mixed_dtype = torch.bfloat16)\r\n\r\nmodel = SimpleNet().eval()\r\nx = torch.rand(64, 64, 224, 224)\r\nwith torch.no_grad():\r\n    model = torch.jit.trace(model, x)\r\n    model = torch.jit.freeze(model)\r\n    y = model(x)\r\n```\r\n</td>\r\n<td>\r\n\r\n```python\r\n# Import the extension\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nmodel = SimpleNet().eval()\r\nx = torch.rand(64, 64, 224, 224)\r\nwith torch.cpu.amp.autocast(), torch.no_grad():\r\n    model = torch.jit.trace(model, x)\r\n    model = torch.jit.freeze(model)\r\n    y = model(x)\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n- The 1.10 release provides the INT8 calibration as an experimental feature while it only supports post-training static quantization now. Compared to 1.9.0, the fronted APIs for quantization is more straightforward and ease-of-use.\r\n\r\n```python\r\nimport torch\r\nimport torch.nn as nn\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nclass MyModel(nn.Module):\r\n    def __init__(self):\r\n        super(MyModel, self).__init__()\r\n        self.conv = nn.Conv2d(10, 10, 3)\r\n        \r\n    def forward(self, x):\r\n        x = self.conv(x)\r\n        return x\r\n\r\nmodel = MyModel().eval()\r\n\r\n# user dataset for calibration.\r\nxx_c = [torch.randn(1, 10, 28, 28) for i in range(2))\r\n# user dataset for validation.\r\nxx_v = [torch.randn(1, 10, 28, 28) for i in range(20))\r\n```\r\n  - Clibration\r\n<table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.9.0-cpu</td>\r\n<td>v1.10.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td>\r\n\r\n```python\r\n# Import the extension\r\nimport intel_pytorch_extension as ipex\r\n\r\n# Convert the model to the Extension device\r\nmodel = Model().to(ipex.DEVICE)\r\n\r\n# Create a configuration file to save quantization parameters.\r\nconf = ipex.AmpConf(torch.int8)\r\nwith torch.no_grad():\r\n    for x in xx_c:\r\n        # Run the model under calibration mode to collect quantization parameters\r\n        with ipex.AutoMixPrecision(conf, running_mode='calibration'):\r\n            y = model(x.to(ipex.DEVICE))\r\n# Save the configuration file\r\nconf.save('configure.json')\r\n```\r\n</td>\r\n<td>\r\n\r\n```python\r\n# Import the extension\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nconf = ipex.quantization.QuantConf(qscheme=torch.per_tensor_affine)\r\nwith torch.no_grad():\r\n    for x in xx_c:\r\n        with ipex.quantization.calibrate(conf):\r\n            y = model(x)\r\n\r\nconf.save('configure.json')\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n - Inference\r\n <table align=\"center\">\r\n<tbody>\r\n<tr>\r\n<td>v1.9.0-cpu</td>\r\n<td>v1.10.0-cpu</td>\r\n</tr>\r\n<tr>\r\n<td>\r\n\r\n```python\r\n# Import the extension\r\nimport intel_pytorch_extension as ipex\r\n\r\n# Convert the model to the Extension device\r\nmodel = Model().to(ipex.DEVICE)\r\nconf = ipex.AmpConf(torch.int8, 'configure.json')\r\nwith torch.no_grad():\r\n    for x in cali_dataset:\r\n        with ipex.AutoMixPrecision(conf, running_mode='inference'):\r\n            y = model(x.to(ipex.DEVICE))\r\n```\r\n</td>\r\n<td>\r\n\r\n```python\r\n# Import the extension\r\nimport intel_extension_for_pytorch as ipex\r\n\r\nconf = ipex.quantization.QuantConf('configure.json')\r\n\r\nwith torch.no_grad():\r\n    trace_model = ipex.quantization.convert(model, conf, example_input)\r\n    for x in xx_v:\r\n        y = trace_model(x)\r\n```\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n\r\n- This release introduces the `optimize` API at the python front end to optimize the model. The new API supports FP32 and BF16, inference, and training.\r\n\r\n- Runtime Extension (Experimental) provides a runtime CPU pool API to bind threads to cores. It also features async tasks. Please **Note**: Intel\u00ae Extension for PyTorch\\* Runtime extension is still in the **POC** stage. The API is subject to change. More detailed descriptions are available in the extension documentation.\r\n\r\n## Known Issues\r\n\r\n- `omp_set_num_threads` function failed to change OpenMP threads number of oneDNN operators if it was set before.\r\n\r\n  `omp_set_num_threads` function is provided in Intel\u00ae Extension for PyTorch\\* to change the number of threads used with OpenMP. However, it failed to change the number of OpenMP threads if it was set before.\r\n\r\n  pseudo-code:\r\n\r\n  ```\r\n  omp_set_num_threads(6)\r\n  model_execution()\r\n  omp_set_num_threads(4)\r\n  same_model_execution_again()\r\n  ```\r\n\r\n  **Reason:** oneDNN primitive descriptor stores the OMP number of threads. Current oneDNN integration caches the primitive descriptor in the extension. So if we use runtime extension with oneDNN based on top of PyTorch or the extension, the runtime extension fails to change the used OMP number of threads.\r\n\r\n- Low performance with INT8 support for dynamic shapes\r\n\r\n  The support for dynamic shapes in Intel\u00ae Extension for PyTorch\\* INT8 integration is still working in progress. For the use cases where the input shapes are dynamic, for example, inputs of variable image sizes in an object detection task or of variable sequence lengths in NLP tasks, the Intel\u00ae Extension for PyTorch\\* INT8 path may slow down the model inference. In this case, please utilize stock PyTorch INT8 functionality.\r\n\r\n- Low throughput with DLRM FP32 Train\r\n\r\n  A 'Sparse Add' [PR](https://github.com/pytorch/pytorch/pull/23057) is pending review. The issue will be fixed when the PR is merged.\r\n\r\n## What's Changed\r\n**Full Changelog**: https://github.com/intel/intel-extension-for-pytorch/compare/v1.9.0...v1.10.0", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/54213213/reactions", "total_count": 17, "+1": 7, "-1": 0, "laugh": 0, "hooray": 5, "confused": 0, "heart": 0, "rocket": 5, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/48031958", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/48031958/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/48031958/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.9.0", "id": 48031958, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTQ4MDMxOTU4", "tag_name": "v1.9.0", "target_commitish": "master", "name": "v1.9.0", "draft": false, "prerelease": false, "created_at": "2021-08-18T09:40:52Z", "published_at": "2021-08-18T09:53:09Z", "assets": [], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.9.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.9.0", "body": "# Intel Extension For PyTorch 1.9.0 Release Notes\r\n## What's New\r\nNew PyTorch 1.9.0 was newly supported by the Intel extension for Pytorch 1.9.0.\r\n- Rebased the Intel Extension for Pytorch from PyTorch-1.8.0 to the official PyTorch-1.9.0 release.\r\n- Support binary installation.\r\n   ```\r\n   python -m pip install torch_ipex==1.9.0 -f https://software.intel.com/ipex-whl-stable\r\n   ```\r\n   Wheel files available for Python versions\r\n  | IPEX Version | Python 3.6 | Python 3.7 | Python 3.8 | Python 3.9 |\r\n  | :--: | :--: | :--: | :--: | :--: |\r\n  | 1.9.0 | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |\r\n  | 1.8.0 |  | :heavy_check_mark: |  |  |\r\n- Support the C++ library. The third party App can link the Intel-Extension-for-PyTorch C++ library to enable the particular optimizations. ", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/48031958/reactions", "total_count": 6, "+1": 6, "-1": 0, "laugh": 0, "hooray": 0, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/44852795", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/44852795/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/44852795/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.8.0", "id": 44852795, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTQ0ODUyNzk1", "tag_name": "v1.8.0", "target_commitish": "master", "name": "v1.8.0", "draft": false, "prerelease": false, "created_at": "2021-06-18T09:08:53Z", "published_at": "2021-06-18T09:21:04Z", "assets": [], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.8.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.8.0", "body": "# Intel Extension For PyTorch 1.8.0 Release Notes\r\n## What's New\r\nNew PyTorch 1.8.0 was newly supported by the Intel extension for Pytorch 1.8.0.\r\n- Rebased the Intel Extension for Pytorch from Pytorch -1.7.0 to the official Pytorch-1.8.0 release. The new XPU device type has been added into Pytorch-1.8.0([49786](https://github.com/pytorch/pytorch/pull/49786)), don\u2019t need to patch PyTorch to enable Intel Extension for Pytorch anymore\r\n- Upgraded the oneDNN from v1.5-rc to v1.8.1\r\n- Updated the README file to add the sections to introduce supported customized operators, supported fusion patterns, tutorials and joint blogs with stakeholders", "reactions": {"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/44852795/reactions", "total_count": 4, "+1": 0, "-1": 0, "laugh": 0, "hooray": 4, "confused": 0, "heart": 0, "rocket": 0, "eyes": 0}}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/38741761", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/38741761/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/38741761/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.2.0", "id": 38741761, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTM4NzQxNzYx", "tag_name": "v1.2.0", "target_commitish": "1.2.0-rc", "name": "v1.2.0", "draft": false, "prerelease": false, "created_at": "2021-02-25T14:20:14Z", "published_at": "2021-02-25T14:25:16Z", "assets": [], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.2.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.2.0", "body": "# Intel Extension For PyTorch 1.2.0 Release Notes\r\n## What's New\r\nNew pytorch 1.7.0 was newly supported by Intel extension for Pytorch.\r\n- We rebased the Intel Extension for pytorch from Pytorch -1.5rc3 to the official Pytorch-1.7.0 release. It will have performance improvement with the new Pytorch-1.7 support.\r\n- Device name was changed from DPCPP to ***XPU***.\r\nWe changed the device name from DPCPP to ***XPU*** to align with the future Intel GPU product for heterogeneous computation.\r\n- Enabled the launcher for end users.\r\nWe enabled the launch script which helps users launch the program for training and inference, then automatically setup the strategy for multi-thread, multi-instance, and memory allocator. Please refer to the [launch script](https://github.com/intel/intel-extension-for-pytorch/blob/1.2.0-rc/intel_pytorch_extension_py/launch.py) comments for more details.\r\n## Performance Improvement\r\n- This upgrade provides better INT8 optimization with refined auto mixed-precision API.\r\n- More operators are optimized for the int8 inference and bfp16 training of some key workloads, like MaskRCNN, SSD-ResNet34, DLRM, RNNT.\r\n## Others\r\n- Bug fixes\r\n    - This upgrade fixes the issue that saving the model trained by Intel extension for PyTorch caused errors.\r\n    - This upgrade fixes the issue that Intel extension for PyTorch was slower than pytorch proper for Tacotron2.\r\n- New custom operators\r\nThis upgrade adds several custom operators: *ROIAlign*, *RNN*, *FrozenBatchNorm*, *nms*.\r\n- Optimized operators/fusion\r\nThis upgrade optimizes several operators: *tanh*, *log_softmax*, *upsample*, *embeddingbad* and enables *int8* *linear* *fusion*.\r\n- Performance\r\nThe release has daily automated testing for the supported models: ResNet50, ResNext101, Huggingface Bert, DLRM, Resnext3d, MaskRNN, SSD-ResNet34. With the extension imported, it can bring up to 2x INT8 over FP32 inference performance improvements on the 3rd Gen Intel Xeon scalable processors (formerly codename Cooper Lake).\r\n## Known issues\r\nMulti-node training still encounter hang issues after several iterations. The fix will be included in the next official release."}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/33840587", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/33840587/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/33840587/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.1.0", "id": 33840587, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTMzODQwNTg3", "tag_name": "v1.1.0", "target_commitish": "1.1.0", "name": "", "draft": false, "prerelease": false, "created_at": "2020-10-28T02:14:00Z", "published_at": "2020-11-12T07:24:13Z", "assets": [], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.1.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.1.0", "body": "### What's New\r\n- Added optimization for training with FP32 data type & BF16 data type. All the optimized FP32/BF16 backward operators include:\r\n    - Conv2d\r\n    - Relu\r\n    - Gelu\r\n    - Linear\r\n    - Pooling\r\n    - BatchNorm\r\n    - LayerNorm\r\n    - Cat\r\n    - Softmax\r\n    - Sigmoid\r\n    - Split\r\n    - Embedding_bag\r\n    - Interaction\r\n    - MLP\r\n- More fusion patterns are supported and validated in the release, see table:\r\n\r\n    Fusion Patterns | Release\r\n    -- | --\r\n    Conv + Sum | v1.0\r\n    Conv + BN | v1.0\r\n    Conv + Relu | v1.0\r\n    Linear + Relu | v1.0\r\n    Conv + Eltwise | v1.1\r\n    Linear + Gelu | v1.1\r\n\r\n- Add docker support\r\n- [Alpha] Multi-node training with oneCCL support.\r\n- [Alpha] INT8 inference optimization.\r\n\r\n### Performance\r\n- The release has daily automated testing for the supported models: ResNet50, ResNext101, [Huggingface Bert](https://github.com/huggingface/transformers), [DLRM](https://github.com/intel/optimized-models/tree/master/pytorch/dlrm), [Resnext3d](https://github.com/XiaobingSuper/Resnext3d-for-video-classification), [Transformer](https://github.com/pytorch/fairseq/blob/master/fairseq/models/transformer.py). With the extension imported, it can bring up to 1.2x~1.7x BF16 over FP32 training performance improvements on the 3rd Gen Intel Xeon scalable processors (formerly codename Cooper Lake).\r\n\r\n### Known issue\r\n- Some workloads may crash after several iterations on the extension with [jemalloc](https://github.com/jemalloc/jemalloc) enabled."}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/29496489", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/29496489/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/29496489/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.0.2", "id": 29496489, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI5NDk2NDg5", "tag_name": "v1.0.2", "target_commitish": "v1.0-rc", "name": "v1.0.2", "draft": false, "prerelease": false, "created_at": "2020-08-10T03:34:28Z", "published_at": "2020-08-10T03:41:01Z", "assets": [], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.0.2", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.0.2", "body": "- Rebase torch CCL patch to PyTorch 1.5.0-rc3"}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/28722079", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/28722079/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/28722079/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.0.1", "id": 28722079, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI4NzIyMDc5", "tag_name": "v1.0.1", "target_commitish": "v1.0-rc", "name": "v1.0.1-alpha Release", "draft": false, "prerelease": false, "created_at": "2020-07-20T02:26:59Z", "published_at": "2020-07-27T05:04:50Z", "assets": [], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.0.1", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.0.1", "body": "- Static link oneDNN library\r\n- Check AVX512 build option\r\n- Fix the issue that cannot normally invoke `enable_auto_optimization`"}
{"url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/28121158", "assets_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/releases/28121158/assets", "upload_url": "https://uploads.github.com/repos/intel/intel-extension-for-pytorch/releases/28121158/assets{?name,label}", "html_url": "https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.0.0", "id": 28121158, "author": {"login": "EikanWang", "id": 55483091, "node_id": "MDQ6VXNlcjU1NDgzMDkx", "avatar_url": "https://avatars.githubusercontent.com/u/55483091?v=4", "gravatar_id": "", "url": "https://api.github.com/users/EikanWang", "html_url": "https://github.com/EikanWang", "followers_url": "https://api.github.com/users/EikanWang/followers", "following_url": "https://api.github.com/users/EikanWang/following{/other_user}", "gists_url": "https://api.github.com/users/EikanWang/gists{/gist_id}", "starred_url": "https://api.github.com/users/EikanWang/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/EikanWang/subscriptions", "organizations_url": "https://api.github.com/users/EikanWang/orgs", "repos_url": "https://api.github.com/users/EikanWang/repos", "events_url": "https://api.github.com/users/EikanWang/events{/privacy}", "received_events_url": "https://api.github.com/users/EikanWang/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTI4MTIxMTU4", "tag_name": "v1.0.0", "target_commitish": "master", "name": "v1.0.0-alpha Release", "draft": false, "prerelease": false, "created_at": "2020-07-03T05:42:11Z", "published_at": "2020-07-03T12:27:06Z", "assets": [], "tarball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/tarball/v1.0.0", "zipball_url": "https://api.github.com/repos/intel/intel-extension-for-pytorch/zipball/v1.0.0", "body": "### What's New\r\n- #### Auto Operator Optimization\r\n  Intel Extension for PyTorch will automatically optimize the operators of PyTorch when importing its python package. It will significantly improve the computation performance if the input tensor and the model is converted to the extension device.\r\n- #### Auto Mixed Precision\r\n  Currently, the extension has supported bfloat16. It streamlines the work to enable a bfloat16 model. The feature is controlled by `enable_auto_mix_precision`. If you enable it, the extension will run the operator with bfloat16 automatically to accelerate the operator computation.\r\n\r\n### Performance Result\r\nWe collected the performance data of some models on the Intel Cooper Lake platform with 1 socket and 28 cores. Intel Cooper Lake introduced AVX512 BF16 instructions which could improve the bfloat16 computation significantly. The detail is as follows (The data is the speedup ratio and the baseline is upstream PyTorch).\r\n|| Imperative - Operator Injection| Imperative - Mixed Precision |JIT- Operator Injection| JIT - Mixed Precision |\r\n|--|--|--|--|--|\r\n|RN50|2.68|5.01|5.14|9.66\r\n|ResNet3D|3.00|4.67|5.19|8.39\r\n|BERT-LARGE|0.99|1.40|N/A|N/A\r\n\r\nWe also measured the performance of ResNeXt101, Transformer-FB, DLRM, and YOLOv3 with the extension. We observed that the performance could be significantly improved by the extension as expected.\r\n\r\n### Known Issues\r\n#10 All data types have not been registered for DPCPP\r\n#37 MaxPool can't get nan result when input's value is nan\r\n\r\n**NOTE**\r\nThe extension supported PyTorch v1.5.0-rc3. Support for other PyTorch versions is working in progress. \r\n\r\n"}
