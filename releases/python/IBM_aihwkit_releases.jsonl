{"url": "https://api.github.com/repos/IBM/aihwkit/releases/67008620", "assets_url": "https://api.github.com/repos/IBM/aihwkit/releases/67008620/assets", "upload_url": "https://uploads.github.com/repos/IBM/aihwkit/releases/67008620/assets{?name,label}", "html_url": "https://github.com/IBM/aihwkit/releases/tag/0.6.0", "id": 67008620, "author": {"login": "kaoutar55", "id": 7916630, "node_id": "MDQ6VXNlcjc5MTY2MzA=", "avatar_url": "https://avatars.githubusercontent.com/u/7916630?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kaoutar55", "html_url": "https://github.com/kaoutar55", "followers_url": "https://api.github.com/users/kaoutar55/followers", "following_url": "https://api.github.com/users/kaoutar55/following{/other_user}", "gists_url": "https://api.github.com/users/kaoutar55/gists{/gist_id}", "starred_url": "https://api.github.com/users/kaoutar55/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kaoutar55/subscriptions", "organizations_url": "https://api.github.com/users/kaoutar55/orgs", "repos_url": "https://api.github.com/users/kaoutar55/repos", "events_url": "https://api.github.com/users/kaoutar55/events{/privacy}", "received_events_url": "https://api.github.com/users/kaoutar55/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOEao-Ns4D_nhs", "tag_name": "0.6.0", "target_commitish": "master", "name": "IBM Analog Hardware Acceleration Kit 0.6.0 ", "draft": false, "prerelease": false, "created_at": "2022-05-16T17:32:08Z", "published_at": "2022-05-16T19:52:49Z", "assets": [], "tarball_url": "https://api.github.com/repos/IBM/aihwkit/tarball/0.6.0", "zipball_url": "https://api.github.com/repos/IBM/aihwkit/zipball/0.6.0", "body": "[0.6.0] - 2022/05/16\r\n\r\nAdded\r\n* Set weights can be used to re-apply the weight scaling omega. (#360)\r\n* Out scaling factors can be learnt even if weight scaling omega was set to 0. (#360)\r\n* Reverse up / down option for LinearStepDevice. (#361)\r\n* Generic Analog RNN classes (LSTM, RNN, GRU) uni or bidirectional. (#358)\r\n* Added new PiecewiseStepDevice where the update-step response function can be arbitrarily defined by the user in a piece-wise linear manner. It can be conveniently used to fit any experimental device data. (#356)\r\n* Several enhancements to the public documentations: added a new section for hw-aware training, refreshed the reference API doc, and added the newly supported LSTM layers and the mapped conv layers. (#374)\r\n\r\nFixed\r\n* Legacy checkpoint load with alpha scaling. (#360)\r\n* Re-application of weight scaling omega when loading checkpoints. (#360)\r\n* Write noise was not correctly applied for CUDA if dw_min_std=0. (#356)\r\n\r\nChanged\r\n* The set_alpha_scale and get_alpha_scale methods of the C++ tiles are removed. (#360)\r\n* The lowest supported Python version is now 3.7, as 3.6 has reached end-of-life. Additionally, the library now officially supports Python 3.10. (#368)\r\n"}
{"url": "https://api.github.com/repos/IBM/aihwkit/releases/58208581", "assets_url": "https://api.github.com/repos/IBM/aihwkit/releases/58208581/assets", "upload_url": "https://uploads.github.com/repos/IBM/aihwkit/releases/58208581/assets{?name,label}", "html_url": "https://github.com/IBM/aihwkit/releases/tag/v0.5.1", "id": 58208581, "author": {"login": "kaoutar55", "id": 7916630, "node_id": "MDQ6VXNlcjc5MTY2MzA=", "avatar_url": "https://avatars.githubusercontent.com/u/7916630?v=4", "gravatar_id": "", "url": "https://api.github.com/users/kaoutar55", "html_url": "https://github.com/kaoutar55", "followers_url": "https://api.github.com/users/kaoutar55/followers", "following_url": "https://api.github.com/users/kaoutar55/following{/other_user}", "gists_url": "https://api.github.com/users/kaoutar55/gists{/gist_id}", "starred_url": "https://api.github.com/users/kaoutar55/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/kaoutar55/subscriptions", "organizations_url": "https://api.github.com/users/kaoutar55/orgs", "repos_url": "https://api.github.com/users/kaoutar55/repos", "events_url": "https://api.github.com/users/kaoutar55/events{/privacy}", "received_events_url": "https://api.github.com/users/kaoutar55/received_events", "type": "User", "site_admin": false}, "node_id": "RE_kwDOEao-Ns4DeDFF", "tag_name": "v0.5.1", "target_commitish": "master", "name": "IBM Analog Hardware Acceleration Kit 0.5.1", "draft": false, "prerelease": false, "created_at": "2022-01-28T04:05:11Z", "published_at": "2022-01-28T16:01:23Z", "assets": [], "tarball_url": "https://api.github.com/repos/IBM/aihwkit/tarball/v0.5.1", "zipball_url": "https://api.github.com/repos/IBM/aihwkit/zipball/v0.5.1", "body": "### Added\r\n\r\n* Load model state dict into a new model with modified `RPUConfig`. (#276)\r\n* Visualization for noise models for analog inference hardware simulation. (#278)\r\n* State independent inference noise model. (# 284)\r\n* Transfer LR parameter for `MixedPrecisionCompound`. (#283)\r\n* The bias term can now be handled either by the analog or digital domain by controlling the `digital_bias` layer parameter. (#307)\r\n* PCM short-term weight noise. (#312)\r\n* IR-drop simulation across columns during analog mat-vec. (#312)\r\n* Transposed-read for `TransferCompound`. (#312)\r\n* `BufferedTranferCompound` and TTv2 presets. (#318)\r\n* Stochastic rounding for `MixedPrecisionCompound`. (#318)\r\n* Decay with arbitrary decay point (to reset bias). (#319)\r\n* Linear layer `AnalogLinearMapped` which maps a large weight matrix onto multiple analog tiles. (#302)\r\n* Convolution layers `AnalogConvNdMapped` which maps large weight matrix onto multiple tiles if necessary. (#331)\r\n* In the new mapping field of `RPUConfig` the max tile input and output sizes can be configured for the `*Mapped` layers. (#331)\r\n* Notebooks directory with several notebook examples (#333, #334)\r\n* Analog information summary function. (#302)\r\n* The alpha weight scaling factor can now be defined as learnable parameter by switching `learn_out_scaling_alpha` in the `rpu_config.mapping` parameters. (#353)\r\n\r\n### Fixed\r\n\r\n* Removed GPU warning during destruction when using multiple GPUs. (#277)\r\n* Fixed issue in transfer counter for mixed precision in case of GPU. (#283)\r\n* Map location keyword for load / save observed. (#293)\r\n* Fixed issue with CUDA buffer allocation when batch size changed. (#294)\r\n* Fixed missing load statedict for `AnalogSequential`. (#295)\r\n* Fixed issue with hierarchical hidden parameter settings. (#313)\r\n* Fixed serious issue that loaded model would not update analog gradients. (#302)\r\n* Fixed cuda import in examples. (#320)\r\n\r\n### Changed\r\n\r\n* The inference noise models are now located in `aihwkit.inference`. (#281)\r\n* Analog state dict structure `has changed (shared weight are not saved). (#293)\r\n* Some of the parameter names of the `TransferCompound` have changed. (#312)\r\n* New fast learning rate parameter for `TransferCompound`, SGD learning rate then is applied on the slow matrix (#312).\r\n* The fixed_value of `WeightClipParameter` is now applied for all clipping types if set larger than zero. (#318)\r\n* The use of generators for analog tiles of an `AnalogModuleBase`. (#302)\r\n* Digital bias is now accessible through `MappingParameter`. (#331)\r\n* The aihwkit documentation. New content around analog AI concepts, training presets, analog AI optimizers, new references, and examples. (#348)\r\n* The `weight_scaling_omega` can now be defined in the `rpu_config.mapping`. (#353)\r\n\r\n### Deprecated\r\n\r\n* The module `aihwkit.simulator.noise_models` has been depreciated in favor of `aihwkit.inference`. (#281)\r\n"}
{"url": "https://api.github.com/repos/IBM/aihwkit/releases/45223629", "assets_url": "https://api.github.com/repos/IBM/aihwkit/releases/45223629/assets", "upload_url": "https://uploads.github.com/repos/IBM/aihwkit/releases/45223629/assets{?name,label}", "html_url": "https://github.com/IBM/aihwkit/releases/tag/v0.4.0", "id": 45223629, "author": {"login": "diego-plan9", "id": 418311, "node_id": "MDQ6VXNlcjQxODMxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/418311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/diego-plan9", "html_url": "https://github.com/diego-plan9", "followers_url": "https://api.github.com/users/diego-plan9/followers", "following_url": "https://api.github.com/users/diego-plan9/following{/other_user}", "gists_url": "https://api.github.com/users/diego-plan9/gists{/gist_id}", "starred_url": "https://api.github.com/users/diego-plan9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/diego-plan9/subscriptions", "organizations_url": "https://api.github.com/users/diego-plan9/orgs", "repos_url": "https://api.github.com/users/diego-plan9/repos", "events_url": "https://api.github.com/users/diego-plan9/events{/privacy}", "received_events_url": "https://api.github.com/users/diego-plan9/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTQ1MjIzNjI5", "tag_name": "v0.4.0", "target_commitish": "master", "name": "IBM Analog Hardware Acceleration Kit 0.4.0", "draft": false, "prerelease": false, "created_at": "2021-06-25T07:47:55Z", "published_at": "2021-06-25T09:36:03Z", "assets": [], "tarball_url": "https://api.github.com/repos/IBM/aihwkit/tarball/v0.4.0", "zipball_url": "https://api.github.com/repos/IBM/aihwkit/zipball/v0.4.0", "body": "### Added\r\n\r\n* A number of new config presets added to the library, namely `EcRamMOPreset`,\r\n  `EcRamMO2Preset`, `EcRamMO4Preset`, `TikiTakaEcRamMOPreset`,\r\n  `MixedPrecisionEcRamMOPreset`. These can be used for tile configuration\r\n  (`rpu_config`). They specify a particular device and optimizer choice. (\\#207)\r\n* Weight refresh mechanism for `OneSidedUnitCell` to counteract saturation, by\r\n  differential read, reset, and re-write. (\\#209)\r\n* Complex cycle-to-cycle noise for `ExpStepDevice`. (\\#226)\r\n* Added the following presets: `PCMPresetDevice` (uni-directional),\r\n  `PCMPresetUnitCell` (a pair of uni-directional devices with periodical\r\n  refresh) and a `MixedPrecisionPCMPreset` for using the mixed precision\r\n  optimizer with a PCM pair. (\\#226)\r\n* `AnalogLinear` layer now accepts multi-dimensional inputs in the same\r\n  way as PyTorch's `Linear` layer does. (\\#227)\r\n* A new `AnalogLSTM` module: a recurrent neural network that uses\r\n `AnalogLinear`. (\\#240)\r\n* Return of weight gradients for `InferenceTile` (only), so that the gradient\r\n  can be handled with any PyTorch optimizer. (\\#241)\r\n* Added a generic analog optimizer `AnalogOptimizer` that allows extending\r\n  any existing optimizer with analog-specific features. (\\#242)\r\n* Conversion tools for converting torch models into a model having analog\r\n  layers. (\\#265)\r\n\r\n### Changed\r\n\r\n* Renamed the `DifferenceUnitCell` to `OneSidedUnitCell` which more properly\r\n  reflects its function. (\\#209)\r\n* The `BaseTile` subclass that is instantiated in the analog layers is now\r\n  retrieved from the new `RPUConfig.tile_class` attribute, facilitating the\r\n  use of custom tiles. (\\#218)\r\n* The default parameter for the `dataset` constructor used by `BasicTraining`\r\n  is now the `train=bool` argument. If using a dataset that requires other\r\n  arguments or transforms, they can now be specified via overriding\r\n  `get_dataset_arguments()` and `get_dataset_transform()`. (\\#225)\r\n* `AnalogContext` is introduced, along with tile registration function to\r\n  handle arbitrary optimizers, so that re-grouping param groups becomes\r\n  unnecessary. (\\#241)\r\n* The `AnalogSGD` optimizer is now implemented based on the generic analog\r\n  optimizer, and its base module is `aihwkit.optim.analog_optimizer`. (\\#242)\r\n* The default refresh rate is changed to once per mini-batch for `PCMPreset`\r\n  (as opposed to once per mat-vec). (\\#243)\r\n\r\n### Deprecated\r\n\r\n* Deprecated the `CudaAnalogTile` and `CudaInferenceTile` and\r\n  `CudaFloatingPointTile`. Now the `AnalogTile` can be either on cuda or on cpu\r\n  (determined by the `tile` and the `device` attribute) similar to a torch\r\n  `Tensor`. In particular, call of `cuda()` does not change the `AnalogTile` to\r\n  `CudaAnalogTile` anymore, but only changes the instance in the `tile` field,\r\n  which makes in-place calls to `cuda()` possible. (\\#257)\r\n\r\n### Removed\r\n\r\n* Removed `weight` and `bias` of analog layers from the module parameters as\r\n  these parameters are handled internally for analog tiles. (\\#241)\r\n\r\n### Fixed\r\n\r\n* Fixed autograd functionality for recurrent neural networks. (\\#240)\r\n* N-D support for `AnalogLinear`. (\\#227)\r\n* Fixed an issue in the `Experiments` that was causing the epoch training loss\r\n  to be higher than the epoch validation loss. (\\#238)\r\n* Fixed \"Wrong device ordinal\" errors for CUDA which resulted from a known\r\n  issue of using CUB together with pytorch. (\\#250)\r\n* Renamed persistent weight hidden parameter field to `persistent_weights`.\r\n  (\\#251)\r\n* Analog tiles now always move correctly to CUDA when `model.cuda()`\r\n  or `model.to(device)` is used. (\\#252, \\#257)\r\n* Added an error message when wrong tile class is used for loading an analog\r\n  state dict. (\\#262)\r\n* Fixed `MixedPrecisionCompound` being bypassed with floating point compute.\r\n  (\\#263)"}
{"url": "https://api.github.com/repos/IBM/aihwkit/releases/41412581", "assets_url": "https://api.github.com/repos/IBM/aihwkit/releases/41412581/assets", "upload_url": "https://uploads.github.com/repos/IBM/aihwkit/releases/41412581/assets{?name,label}", "html_url": "https://github.com/IBM/aihwkit/releases/tag/v0.3.0", "id": 41412581, "author": {"login": "diego-plan9", "id": 418311, "node_id": "MDQ6VXNlcjQxODMxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/418311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/diego-plan9", "html_url": "https://github.com/diego-plan9", "followers_url": "https://api.github.com/users/diego-plan9/followers", "following_url": "https://api.github.com/users/diego-plan9/following{/other_user}", "gists_url": "https://api.github.com/users/diego-plan9/gists{/gist_id}", "starred_url": "https://api.github.com/users/diego-plan9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/diego-plan9/subscriptions", "organizations_url": "https://api.github.com/users/diego-plan9/orgs", "repos_url": "https://api.github.com/users/diego-plan9/repos", "events_url": "https://api.github.com/users/diego-plan9/events{/privacy}", "received_events_url": "https://api.github.com/users/diego-plan9/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTQxNDEyNTgx", "tag_name": "v0.3.0", "target_commitish": "master", "name": "IBM Analog Hardware Acceleration Kit 0.3.0", "draft": false, "prerelease": false, "created_at": "2021-04-14T09:15:12Z", "published_at": "2021-04-14T12:21:26Z", "assets": [], "tarball_url": "https://api.github.com/repos/IBM/aihwkit/tarball/v0.3.0", "zipball_url": "https://api.github.com/repos/IBM/aihwkit/zipball/v0.3.0", "body": "### Added\r\n\r\n* New analog devices:\r\n  * A new abstract device (`MixedPrecisionCompound`) implementing an SGD\r\n    optimizer that computes the rank update in digital (assuming digital\r\n    high precision storage) and then transfers the matrix sequentially to\r\n    the analog device, instead of using the default fully parallel pulsed\r\n    update. (\\#159)\r\n  * A new device model class `PowStepDevice` that implements a power-exponent\r\n    type of non-linearity based on the Fusi & Abott synapse model. (\\#192)\r\n  * New parameterization of the `SoftBoundsDevice`, called\r\n    `SoftBoundsPmaxDevice`. (\\#191)\r\n* Analog devices and tiles improvements:\r\n  * Option to choose deterministic pulse trains for the rank-1 update of\r\n    analog devices during training. (\\#99)\r\n  * More noise types for hardware-aware training for inference\r\n    (polynomial). (\\#99)\r\n  * Additional bound management schemes (worst case, average max, shift).\r\n    (\\#99)\r\n  * Cycle-to-cycle output referred analog multiply-and-accumulate weight\r\n    noise that resembles the conductance dependent PCM read noise\r\n    statistics. (\\#99)\r\n  * C++ backend improvements (slice backward/forward/update, direct\r\n    update). (\\#99)\r\n  * Option to excluded bias row for hardware-aware training noise. (\\#99)\r\n  * Option to automatically scale the digital weights into the full range of\r\n    the simulated crossbar by applying a fixed output global factor in\r\n    digital. (\\#129)\r\n  * Optional power-law drift during analog training. (\\#158)\r\n  * Cleaner setting of `dw_min` using device granularity. (\\#200)\r\n* PyTorch interface improvements:\r\n  * Two new convolution layers have been added: `AnalogConv1d` and\r\n    `AnalogConv3d`, mimicking their digital counterparts. (\\#102, \\#103)\r\n  * The `.to()` method can now be used in `AnalogSequential`, along with\r\n    `.cpu()` methods in analog layers (albeit GPU to CPU is still not\r\n    possible). (\\#142, \\#149)\r\n* New modules added:\r\n  * A library of device presets that are calibrated to real hardware data,\r\n    namely `ReRamESPresetDevice`, `ReRamSBPresetDevice`, `ECRamPresetDevice`,\r\n    `CapacitorPresetDevice`, and device presets that are based on models in the\r\n    literature, e.g. `GokmenVlasovPresetDevice` and `IdealizedPresetDevice`.\r\n    They can be used defining the device field in the `RPUConfig`. (\\#144)\r\n  * A library of config presets, such as `ReRamESPreset`, `Capacitor2Preset`,\r\n    `TikiTakaReRamESPreset`, and many more. These can be used for tile\r\n    configuration (`rpu_config`). They specify a particular device and optimizer\r\n    choice. (\\#144)\r\n  * Utilities for visualization the pulse response properties of a given\r\n    device configuration. (\\#146)\r\n  * A new `aihwkit.experiments` module has been added that allows creating and\r\n    running specific high-level use cases (for example, neural network training)\r\n    conveniently. (\\#171, \\#172)\r\n  * A `CloudRunner` class has been added that allows executing experiments in\r\n    the cloud. (\\#184)\r\n\r\n#### Changed\r\n\r\n* The minimal PyTorch version has been bumped to `1.7+`. Please recompile your\r\n  library and update the dependencies accordingly. (\\#176)\r\n* Default value for TransferCompound for `transfer_every=0` (\\#174).\r\n\r\n#### Fixed\r\n\r\n* Issue of number of loop estimations for realistic reads. (\\#192)\r\n* Fixed small issues that resulted in warnings for windows compilation. (\\#99)\r\n* Faulty backward noise management error message removed for perfect backward\r\n  and CUDA. (\\#99)\r\n* Fixed segfault when using diffusion or reset with vector unit cells for\r\n  CUDA. (\\#129)\r\n* Fixed random states mismatch in IoManager that could cause crashed in same\r\n  network size and batch size cases for CUDA, in particular for\r\n  `TransferCompound`. (\\#132)\r\n* Fixed wrong update for `TransferCompound` in case of `transfer_every` smaller\r\n  than the batch size. (\\#132, \\#174)\r\n* Period in the modulus of `TransferCompound` could become zero which\r\n  caused a floating point exception. (\\#174)\r\n* Ceil instead of round for very small transfers in `TransferCompound`\r\n  (to avoid zero transfer for extreme settings). (\\#174)\r\n\r\n#### Removed\r\n\r\n* The legacy `NumpyAnalogTile` and `NumpyFloatingPointTile` tiles have been\r\n  finally removed. The regular, tensor-powered `aihwkit.simulator.tiles` tiles\r\n  contain all their functionality and numerous additions. (\\#122)\r\n"}
{"url": "https://api.github.com/repos/IBM/aihwkit/releases/34465378", "assets_url": "https://api.github.com/repos/IBM/aihwkit/releases/34465378/assets", "upload_url": "https://uploads.github.com/repos/IBM/aihwkit/releases/34465378/assets{?name,label}", "html_url": "https://github.com/IBM/aihwkit/releases/tag/v0.2.1", "id": 34465378, "author": {"login": "diego-plan9", "id": 418311, "node_id": "MDQ6VXNlcjQxODMxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/418311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/diego-plan9", "html_url": "https://github.com/diego-plan9", "followers_url": "https://api.github.com/users/diego-plan9/followers", "following_url": "https://api.github.com/users/diego-plan9/following{/other_user}", "gists_url": "https://api.github.com/users/diego-plan9/gists{/gist_id}", "starred_url": "https://api.github.com/users/diego-plan9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/diego-plan9/subscriptions", "organizations_url": "https://api.github.com/users/diego-plan9/orgs", "repos_url": "https://api.github.com/users/diego-plan9/repos", "events_url": "https://api.github.com/users/diego-plan9/events{/privacy}", "received_events_url": "https://api.github.com/users/diego-plan9/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTM0NDY1Mzc4", "tag_name": "v0.2.1", "target_commitish": "master", "name": "IBM Analog Hardware Acceleration Kit 0.2.1", "draft": false, "prerelease": false, "created_at": "2020-11-26T10:07:28Z", "published_at": "2020-11-26T13:47:04Z", "assets": [], "tarball_url": "https://api.github.com/repos/IBM/aihwkit/tarball/v0.2.1", "zipball_url": "https://api.github.com/repos/IBM/aihwkit/zipball/v0.2.1", "body": "### Added\r\n\r\n* The `rpu_config` is now pretty-printed in a readable manner (excluding the\r\n  default settings and other readability tweak). (\\#60)\r\n* Added a new `ReferenceUnitCell` which has two devices, where one is fixed and\r\n  the other updated and the effective weight is computed a difference between\r\n  the two. (\\#61)\r\n* `VectorUnitCell` accepts now arbitrary weighting schemes that can be\r\n  user-defined by using a new `gamma_vec` property that specifies how to combine\r\n  the unit cell devices to form the effective weight. (\\#61)\r\n\r\n### Changed\r\n\r\n* The unit cell items in `aihwkit.simulator.configs` have been renamed, removing\r\n  their `Device` suffix, for having a more consistent naming scheme. (\\#57)\r\n* The `Exceptions` raised by the library have been revised, making use in some\r\n  cases of the ones introduced in a new `aihwkit.exceptions` module. (\\#49)\r\n* Some `VectorUnitCell` properties have been renamed and extended with an update\r\n  policy specifying how to select the hidden devices. (\\#61)\r\n* The `pybind11` version required has been bumped to 2.6.0, which can be\r\n  installed from `pip` and makes system-wide installation no longer required.\r\n  Please update your `pybind11` accordingly for compiling the library. (\\#44)\r\n\r\n### Removed\r\n\r\n* The `BackwardIOParameters` specialization has been removed, as bound\r\n  management is now automatically ignored for the backward pass. Please use the\r\n  more general `IOParameters` instead. (\\#45)\r\n\r\n### Fixed\r\n\r\n* Serialization of `Modules` that contain children analog layers is now\r\n  possible, both when using containers such as `Sequential` and when using\r\n  analog layers as custom Module attributes. (\\#74, \\#80)\r\n* The build system has been improved, with experimental Windows support and\r\n  supporting using CUDA 11 correctly. (\\#58, \\#67, \\#68)"}
{"url": "https://api.github.com/repos/IBM/aihwkit/releases/32826538", "assets_url": "https://api.github.com/repos/IBM/aihwkit/releases/32826538/assets", "upload_url": "https://uploads.github.com/repos/IBM/aihwkit/releases/32826538/assets{?name,label}", "html_url": "https://github.com/IBM/aihwkit/releases/tag/v0.2.0", "id": 32826538, "author": {"login": "diego-plan9", "id": 418311, "node_id": "MDQ6VXNlcjQxODMxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/418311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/diego-plan9", "html_url": "https://github.com/diego-plan9", "followers_url": "https://api.github.com/users/diego-plan9/followers", "following_url": "https://api.github.com/users/diego-plan9/following{/other_user}", "gists_url": "https://api.github.com/users/diego-plan9/gists{/gist_id}", "starred_url": "https://api.github.com/users/diego-plan9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/diego-plan9/subscriptions", "organizations_url": "https://api.github.com/users/diego-plan9/orgs", "repos_url": "https://api.github.com/users/diego-plan9/repos", "events_url": "https://api.github.com/users/diego-plan9/events{/privacy}", "received_events_url": "https://api.github.com/users/diego-plan9/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTMyODI2NTM4", "tag_name": "v0.2.0", "target_commitish": "master", "name": "IBM Analog Hardware Acceleration Kit 0.2.0", "draft": false, "prerelease": false, "created_at": "2020-10-20T16:09:01Z", "published_at": "2020-10-20T18:12:59Z", "assets": [], "tarball_url": "https://api.github.com/repos/IBM/aihwkit/tarball/v0.2.0", "zipball_url": "https://api.github.com/repos/IBM/aihwkit/zipball/v0.2.0", "body": "### Added\r\n\r\n* Added more types of resistive devices: `IdealResistiveDevice`, `LinearStep`,\r\n  `SoftBounds`, `ExpStep`, `VectorUnitCell`, `TransferCompoundDevice`,\r\n  `DifferenceUnitCell`. (\\#14)\r\n* Added a new `InferenceTile` that supports basic hardware-aware training\r\n  and inference using a statistical noise model that was fitted by real PCM\r\n  devices. (\\#25)\r\n* Added a new `AnalogSequential` layer that can be used in place of `Sequential`\r\n  for easier operation on children analog layers. (\\#34)\r\n\r\n### Changed\r\n\r\n* Specifying the tile configuration (resistive device and the rest of the\r\n  properties) is now based on a new `RPUConfig` family of classes, that is\r\n  passed as a `rpu_config` argument instead of `resistive_device` to `Tiles`\r\n  and `Layers`. Please check the `aihwkit.simulator.config` module for more\r\n  details. (\\#23)\r\n* The different analog tiles are now organized into a `aihwkit.simulator.tiles`\r\n  package. The internal `IndexedTiles` have been removed, and the rest of\r\n  previous top-level imports have been kept. (\\#29)\r\n\r\n### Fixed\r\n\r\n* Improved package compatibility when using non-UTF8 encodings (version file,\r\n  package description). (\\#13)\r\n* The build system can now detect and use `openblas` directly when using the\r\n  conda-installable version. (\\#22)\r\n* When using analog layers as children of another module, the tiles are now\r\n  correctly moved to CUDA if using `AnalogSequential` (or by the optimizer if\r\n  using regular torch container modules). (\\#34)"}
{"url": "https://api.github.com/repos/IBM/aihwkit/releases/31599064", "assets_url": "https://api.github.com/repos/IBM/aihwkit/releases/31599064/assets", "upload_url": "https://uploads.github.com/repos/IBM/aihwkit/releases/31599064/assets{?name,label}", "html_url": "https://github.com/IBM/aihwkit/releases/tag/v0.1.0", "id": 31599064, "author": {"login": "diego-plan9", "id": 418311, "node_id": "MDQ6VXNlcjQxODMxMQ==", "avatar_url": "https://avatars.githubusercontent.com/u/418311?v=4", "gravatar_id": "", "url": "https://api.github.com/users/diego-plan9", "html_url": "https://github.com/diego-plan9", "followers_url": "https://api.github.com/users/diego-plan9/followers", "following_url": "https://api.github.com/users/diego-plan9/following{/other_user}", "gists_url": "https://api.github.com/users/diego-plan9/gists{/gist_id}", "starred_url": "https://api.github.com/users/diego-plan9/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/diego-plan9/subscriptions", "organizations_url": "https://api.github.com/users/diego-plan9/orgs", "repos_url": "https://api.github.com/users/diego-plan9/repos", "events_url": "https://api.github.com/users/diego-plan9/events{/privacy}", "received_events_url": "https://api.github.com/users/diego-plan9/received_events", "type": "User", "site_admin": false}, "node_id": "MDc6UmVsZWFzZTMxNTk5MDY0", "tag_name": "v0.1.0", "target_commitish": "master", "name": "IBM Analog Hardware Acceleration Kit 0.1.0", "draft": false, "prerelease": false, "created_at": "2020-09-21T11:27:31Z", "published_at": "2020-09-21T11:53:48Z", "assets": [], "tarball_url": "https://api.github.com/repos/IBM/aihwkit/tarball/v0.1.0", "zipball_url": "https://api.github.com/repos/IBM/aihwkit/zipball/v0.1.0", "body": "### Added\r\n\r\n* Initial public release.\r\n* Added `rpucuda` C++ simulator, exposed through a `pybind` interface.\r\n* Added a PyTorch `AnalogLinear` neural network model.\r\n* Added a PyTorch `AnalogConv2d` neural network model."}
